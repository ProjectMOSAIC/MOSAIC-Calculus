[
  {
    "objectID": "Manifestations/B4-optimization.html",
    "href": "Manifestations/B4-optimization.html",
    "title": "49  Optimization and constraint",
    "section": "",
    "text": "In Chapter Chapter 24 we introduced optimization and some of the terms used to describe optimization problems:\nA simple optimization problem has three main phases:\nTo illustrate, consider this simple but unrealistic problems found in hundreds of calculus texts: Finding the configuration to construct the rectangular box with the largest possible volume out of a piece of cardboard. The modeling phase starts with a representation of the box-construction and volume-finding process. Suppose, for the sake of simplicity, that we are working with a piece of cardboard fixed at 20 inches by 30 inches. For box construction, we will propose cutting out squares from each corner of the box of some side length \\(x\\). Those squares will be discarded and the box formed by folding up the flaps generated by the squares’ removal, as in Figure 49.1.\nFor the volume of the box, we will multiply the area of the bottom of the box by the height \\(x\\). Examination of Figure 49.1 should be enough to convince you that the volume \\(V\\) is a function of \\(x\\):\n\\[V(x) = \\underbrace{\\strut x}_\\text{height} \\cdot \\underbrace{(20-2x)}_\\text{width}\\cdot \\underbrace{(30-2x)}_\\text{length} =  x(600 - 100 x + 4 x^2)\\ .\\]\nSince the goal is to find the maximum possible volume, \\(V(x)\\) is our objective function.\nThe solution phase can be completed by drawing a graph of \\(V(x)\\) and finding the \\(x\\) corresponding to the peak value of \\(V(x)\\). We will leave this for you to do in a sandbox; you can figure out the relevant domain by noting that the corner squares cannot overlap. Calculus texts typically emphasize another approach, using symbolic differentiation to examine \\(\\partial_x V(x)\\) and solve for \\(x^\\star\\) such that \\(\\partial_x V(x^\\star) = 0\\). The derivative is\n\\[\\partial_x V(x) = 600 - 200 x + 12 x^2\\ .\\] The symbolic solution task is to find the zeros of \\(\\partial_x V(x)\\). They work out to be \\(x_1^\\star = 3.92\\) or \\(x_2^\\star = 12.74\\).\nThe third phase of an optimization problem, evaluation phase, can start with plugging in the objective function the values of \\(x^\\star\\).\n\\[V(x_1^\\star) = 1056.3\\ \\text{in}^3 \\ \\ \\ \\ \\text{and}\\ \\ \\ \\ V(x_2^\\star) = -315.6\\ \\text{in}^3\\]\nIt is common sense that \\(x_2^\\star\\) is not a viable solution. The negative volume at \\(x_2^\\star\\) is a consequence of looking at \\(V(x)\\) beyond the sensible domain for cardboard boxes. More generally, as part of the evaluation phase we can look at the value of the convexity \\(\\partial_{xx} V(x^\\star)\\) to find out whether an \\(x^\\star\\) value is an argmax or an argmin. Since \\(\\partial_{xx} V(x) = 24 x - 200\\) we see that \\(\\partial_{xx} V(x_1^\\star) < 0\\), corresponding to an argmax. Alternatively, instead of computing the convexity, we could check whether we have an argmin or an argmax by evaluating the objective function at a nearby input.\nAdditional examination of the phase-two solution can give useful information, such as an indication of how sensitive the output is to small changes of the input near the argmax (or argmin). For example, setting \\(x=4\\) in will produce a volume output \\(V(4) = 1056\\) in2, hardly different than the “exact” maximum of 1056.3 in3 and perhaps preferred for the person who wants to make standard-size boxes.\nThe evaluation phase in a genuine application (as opposed to a textbook toy example) should also include a reflection on how well the model reflects the real-world situation. For example we’ve neglected the creases that arise from folding cardboard, so a more complete examination would estimate this effect. And the person skeptical about calculus-book chestnuts might wonder whether the object is really to create a box without a top!\nCommonly, optimization problems involve much more complicated objective functions with many inputs. The next section considers the basis for a more general and practical approach to the solving phase of optimization. Later sections examine how this more general approach leads to methods for approaching the sort of real-world optimization problem where there are multiple objectives."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#gradient-descent",
    "href": "Manifestations/B4-optimization.html#gradient-descent",
    "title": "49  Optimization and constraint",
    "section": "49.1 Gradient descent",
    "text": "49.1 Gradient descent\nThe general approach we will take to the solving phase of optimization problems will be iterative as in Chapter Chapter 47. Start with an initial guess for an argmin and then construct a new function that can improve the guess. Applying this improvement function iteratively leads to better and better estimates of the true argmin.\nFor illustration purposes, we will use optimization problems where the objective function has two inputs. Such objective functions can be graphed on paper or a display screen and it is possible to see the action of the iterative improvement process directly. For optimization in problem with many inputs, the improvement can be monitored from the objective function output at each step.\n\nSpring-mass systems: an example context\nAs our example context for discussing the optimization process, we will consider how to use optimization to calculate the configuration of simple mechanical systems consisting of interconnected springs and masses. Such configuration problems are especially important today in understanding the structure and function of proteins, but we will stick to the simpler context of springs and masses.\n\nFigure 49.2 shows a mechanical system consisting of a mass suspended from a fixed mounting by three nonlinear springs.\n\n\n\n\n\nFigure 49.2: A mass suspended from three springs.\n\n\n\n\nThe mass is shown by a black circles. Springs are the zig-zag shapes. The bold bar is the fixed mounting, as if from a beam on the ceiling of a room. The system has an equilibrium configuration where the springs are stressed sufficiently to balance each other left to right and to balance the gravitational force downward on the mass.\nWe want to calculate the equilibrium position. The basic strategy is to model the potential energy of the system, which consists of:\n\nthe gravitational potential energy of the mass.\nthe energy stored in stretched or compressed springs.\n\nSince the configuration of the system is set by the coordinate \\((x_1, y_1)\\), the potential energy is a function \\(E(x_1, y_1)\\). For brevity, we will leave out the physics of the formulation of the potential-energy function; shown in Figure 49.3.\n\n\n\n\n\nFigure 49.3: The potential energy of the spring-mass system in Figure 49.2.\n\n\n\n\nThe potential energy function \\(E(x,y)\\) has a bowl-like shape. The bottom of the bowl—the argmin—is near \\((x=1.7, y=-1.3)\\). In terms of Figure 49.2, the equilibrium position is a bit upward and to the right of the position shown in the figure.\nWith a graph of the objective function like Figure 49.3, the solution phase is simple; a graph will do the job. But for more complicated objective functions, with more than 2 inputs, drawing a complete graph is not feasible. For example, in the spring-mass system shown in Figure 49.4, the potential energy function has six inputs: \\(x_1, y_1, x_2, y_2, x_3, y_3\\). In genuine applications of optimization, there are often many more inputs.\n\n\n\n\n\nFigure 49.4: A more complicated spring-mass system.\n\n\n\n\nIn a multi-input optimization problem, we don’t have a picture of the whole objective function. Instead, we are able merely to evaluate the objective function for a single given input at a time. Typically, we have a computer function that implements the objective function and we are free to evaluate it at whatever inputs we care to choose. It is as if, instead of having the whole graph available, the graph is covered with an opaque sheet with a loophole, as in Figure 49.5.\n\n\n\n\n\nFigure 49.5: A more realistic view of what we can know about a function.\n\n\n\n\nWe can see the function only in a small region of the domain and need to use the information provided there to determine which way to move to find the argmin.\nThe situation is analogous to standing on the side of a smooth hill in a dense fog and finding your way to the bottom. The way forward is to figure out which direction is uphill, which you can do directly from your sense of balance by orienting your stance in different ways. Then, if your goal is the top of the hill (argmax) start walking uphill. If you seek a low point (argmin), walk downhill.\nThe mathematical equivalent to sensing which direction is uphill is to calculate the gradient of the objective function. In Chapter Chapter 25 we used partial differentiation with respect to each of the input quantities to assemble the gradient vector, denoted \\(\\nabla f() = \\left({\\large \\strut} \\partial_x f(), \\ \\partial_y f()\\right)\\). In terms of Figure 49.5, where we are standing at about \\((x_i=0.8, y_i=-2.3)\\), we would evaluate the each of the partial derivatives in the gradient vector at \\((0.8, -2.3)\\).\nThe gradient points in the steepest direction uphill so, once you know the direction, take a step in that direction to head toward the argmax, or a step in the opposite direction if you seek the argmin. The process of following the gradient toward the top of the hill is called gradient ascent. Correspondingly, following the gradient downhill is gradient descent.\n\n\n\n\n\nFigure 49.6: The gradient provides information about the shape of the local function in a convenient form to guide the step to the next locale in your journey toward the argmin or argmax.\n\n\n\n\nFor humans, the length of a step is fixed by the length of our legs and the size of our feet. The mathematical step has no fixed size. Often, the modeler gains some appreciation for what constitutes a small step from the modeling process. Referring to Figure 49.4 for example you can see that a small increment in \\(x\\) is, say, \\(0.1\\), and similarly for \\(y\\). There is little point in taking an infinitesimal step—that gets you almost nowhere! Instead, be bold and take a finite step. Then, at your new location, calculate the gradient vector again. If it is practically the same as at your earlier position, you can wager on taking a larger step next time. If the new gradient direction is substantially different, you would be well advised to take smaller steps.\nFortunately, a variety of effective ideas for determining step size have been implemented in software and packaged up as algorithms. The modeler need only provide the objective function in a suitable forma starting guess for the inputs.\n\nThe R/mosaic function argM() is set up to find argmins and argmaxes using the familiar tilde-formula/domain style of arguments used throughout this book. For instance, the potential energy of the spring-mass system shown in Figure 49.2 is available as mosaicCalc::PE_fun1()\n\nargM(PE_fun1(x, y) ~ x & y, bounds(x=0:3, y=-3:0))\n## # A tibble: 1 × 3\n##       x     y .output.\n##   <dbl> <dbl>    <dbl>\n## 1  1.65 -1.21    -3.55\n\n\n\nTextbook formulas in physics, chemistry, engineering, and economics often have a root in an optimization problem. Since a formula is the desired result, symbolic differentiation is used in the solution phase. This allows parameters to be represented with symbols rather than as specific numbers. Usually the objective functions involved are simple. And to make the objective functions simple enough for symbolic work, it is common to make approximations, for example by replacing functions like \\(\\sin(x)\\) with \\(x\\) and \\((1+p)^n\\) with \\(1+np\\). But simplifying the objective function should really be considered part of the solution phase rather than the modeling phase.\nNumerical techniques are the most widely used in practice. Optimization is an important operation in both science and management and much human ingenuity has gone into the development of effective algorithms. The modeler rarely if ever needs to reach beyond the software provided in technical computing environments such as R, MATLAB, Mathematica, or the many packages available for Python.\nIn data science and machine learning, often advanced solution-phase software is provided as web services and APIs (application programming interfaces). An example is the Google technology product TensorFlow used to find optimal parameters for functions in the machine technique called “deep learning.”\n\n\n\nThe potential energy function of the spring-mass system in Figure 49.4 is available as the R/mosaic function PE_fun2(). This potential energy function has six inputs: the \\(x\\) and \\(y\\) coordinates of each of the three masses. The code below shows how to use the R/mosaic argM() function to locate an argmin of the potential energy.\n\nargM(PE_fun2(\n  x1, y1, x2, y2, x3, y3) ~ x1 & y1 & x2 & y2 & x3 & y3, \n  bounds(x1 = 0:3, y1=-3:0, x2=0:3, y2=-3:0, x3=0:3, y3=-3:0))\n## # A tibble: 1 × 7\n##      x1    y1    x2    y2    x3    y3 .output.\n##   <dbl> <dbl> <dbl> <dbl> <dbl> <dbl>    <dbl>\n## 1 0.800 -2.15  1.60 -3.05  2.40 -2.70    -8.86\n\nThe argM() function reports the final result, the end of the path followed in descending the gradient field. Figure 49.7 gives a movie of the path as it is being followed.\n\n\n\n\n\nFigure 49.7: The path to equilibrium for the 3-body spring-mass system shown in Figure 49.4. The top two frames show a 2-dimensional slice through the 6-dimensional gradient field. The bottom frame translates the current point on the path into a picture of the spring-mass locations.\n\n\n\n\nAt the start of the movie, the masses are (absurdly) misplaced and far from their equilibrium position. As system configuration moves downhill toward the argmin of the potential energy function, the masses sort themselves out.\nThe two gradient-field frames show a different two-dimensional slices of the potential energy function which has six inputs. Watch the gradient-fields carefully to see that the field itself is changing as time goes by. All six inputs are changing. At each point in time, we are plotting the gradient field as a function of the two inputs shown on the axes. These stay the same through the whole movie, but the other four inputs are changing as the system moves along the gradient descent path. The last frame shows the gradient field at the final position in six-dimensional space. You can see that the early parts of the path are not aligned with the end-of-path gradient fields, but they were aligned at the earlier time when each point in the path was passed.\nThe familiar tilde-expression format used by argM() and the other R/mosaic functions is suitably compact for function of one or two arguments, but for functions with many inputs it becomes ungainly. For objective functions with many inputs, a different programming style is more appropriate that packages up the multiple inputs into a single, vector input. Since this is not a programming book, we won’t go into the vector-input programming style, but be aware that in professional-level work, learning new tools for programming becomes essential."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#objectives-and-constraints",
    "href": "Manifestations/B4-optimization.html#objectives-and-constraints",
    "title": "49  Optimization and constraint",
    "section": "49.2 Objectives and Constraints",
    "text": "49.2 Objectives and Constraints\nMany real-world decision-making settings do not fit neatly into the framework of constructing an objective function and then finding the argmin (or argmax). A common situation is having multiple objectives. These objectives often compete and the output of the respective objective functions may not necessarily be directly comparable. For instance, in health care one objective is to save lives, while another is to minimize costs. But lives and money are not directly comparable.\nOften, the original problem statement does not include all of the objectives and the modeler needs to be perceptive to discern important objectives left out of the initial description of the problem. When such missing objectives become apparent, it is necessary to visit the modeling phase of the problem to insert the new objectives. By adopting the right approach to modeling, such situations can be readily handled and, even better, the modeling phase can bring new insight into the real-world problem.\nTo illustrate, let’s returning to the mathematically simplified problem of constructing an optimal cardboard box. Before, we stipulated that the raw cardboard stock has dimension 20 inches by 30 inches. Now we will generalize and work with a piece of cardboard that has edges of length \\(y\\) from which, as before, we will cut out square corners of length \\(x\\) on a side. (See ?fig-box-shape). Our objective is to make a box with the largest possible volume. (This will be an argmax problem.)\n\n\n\n\n\nFigure 49.8: The cardboard cut lines and the eventual shape of the folded box.\n\n\n\n\n\n\n\nFigure 49.9: The cardboard cut lines and the eventual shape of the folded box.\n\n\n\n\nThe area of the bottom of the box is \\((y - 2x)^2\\) and the box height is \\(x\\). The objective function is the volume of the box, area times height: \\[V(x, y) \\equiv x (y - 2x)^2\\ .\\] There are two inputs, \\(x\\) and \\(y\\), so a simple plot should suffice to find the argmax.\n\n\n\n\n\nFigure 49.10: The volume of the box (in cubic inches) constructed by cutting corners of size \\(x\\)-by\\(x\\) out of a \\(y\\)-by-\\(y\\) piece of cardboard.\n\n\n\n\nScanning Figure 49.10 reveals a couple of things that you might not have anticipated. First, the argmax is in the extreme lower-right corner of the graphics frame, not in the center as in previous examples. Second, the argmax in this corner, \\((y=0, x=10)\\) is logically inconsistent with the idea of a cardboard box.\nThe inconsistency stems from an inadmissible value for \\(x\\). For \\(2x > y\\), the bottom of the box would have negative edge length. But because the objective function \\(V(x,y)\\) squares this negative quantity—in the \\((y - 2x)^2\\) term—the output of the objective function does not signal that anything is wrong. The source of the problem is not the objective function formula itself, but neglecting to consider carefully what is the proper practical domain for the function.\nTo make the calculation realistic, we should search for the argmax only in that region of the graphics frame where \\(y > 2x\\). That restriction on the search domain is called a constraint. In this case, the constraint takes the form of an inequality \\(y > 2x\\) so we call it an inequality constraint. (Later, we will work with equality constraints.)\n\n\n\n\n\nFigure 49.11: The inequality constraint that \\(y > 2x\\) renders much of the graphics frame inadmissible as a possible solution. The inadmissible region is shaded in blue. The argmax must be sought in the unshaded region of the frame.\n\n\n\n\nWith the \\((x,y)\\)-domain restricted to the values that are physically realistic, we can see that the argmax is still on the edge of the frame, at \\(y=30\\) and \\(x\\approx 5\\), where the volume of the box will be about 1800 in3. This result should cause you pause, since there was nothing in the problem statement that limited \\(y\\) to be 30” or less. If we replotted with a larger domain for \\(y\\), we should see still larger boxes, without any limit.\nThe interpretation of the problem as originally posed is: With enough cardboard we can make a box of any size! Since the goal was to recommend the “best” size, this conclusion is not so useful. The weak conclusion stems from a fault in the problem statement. The statement omitted an important second objective function: use as little cardboard as possible.\nIf using as little cardboard as possible were our sole objective, the optimization problem has an easy-to-find solution: we would make a zero-volume box out of zero-area of cardboard. What we want, somehow, is to make as big a box as possible out of as little cardboard as possible: we have two objectives! In this case, the objectives are in conflict: making a bigger box (good) uses more cardboard (bad).\nCommon sense tells us to balance the two objectives, but how to represent this mathematically? Ideally—note that “ideally” is sometimes far from “realistically” or “productively”—we would know how much box-volume is worth to us and how much cardboard costs, and we could construct an objective function that incorporates both value and cost. For instance, if each cubic inch of volume is worth 1 cent, and each square inch of cardboard costs 3 cents, then the objective function will be the following (with output in cents):\n\\[\\text{Profit}(x,y) \\equiv 1\\, x (y-2x)^2 - 3 y^2\\]\n\n\n\n\n\nFigure 49.12: The “profit” (value minus cost) of the cardboad box (cents).\n\n\n\n\nEven with including the cardboard cost in the objective function, we will still want to make \\(y\\) as large as possible. Not much guidance there!\nBut let’s imagine a new factor coming into play. At the meeting where the box-design decisions are being made and where you are presenting your analysis in Figure 49.12, the graphic designer speaks up. “The trending shape for this year is cubic. We want the box, whatever it is size, to be a cube.”\nLuckily, you the modeler can quickly incorporate this into your analysis. To be a cube, the height \\(x\\) of the box has to be the same as the width and depth \\(y - 2x\\). So you can incorporate the designer’s wish into the model of the decision factors by adding a new constraint:\n\\[x = y - 2x \\ \\ \\ \\implies y-3x=0\\ \\ \\ \\ \\text{constraint: box must be cubic}\\]\nThis is called an equality constraint. Figure 49.13 shows the equality constraint in green: to be a cube, \\(x\\) and \\(y\\) must be somewhere along the green line.\n\n\n\n\n\nFigure 49.13: The profit function shown in more detail along with the equality constraint (green) for the box to be cube-shaped.\n\n\n\n\nFollow the green path uphill. As \\(x\\) gets larger along the constraint, the output of the objective function grows, reaching a level of 1350 cents when \\((x=15, y=45)\\) at the right border of the graphics frame.\nIt is worth pointing out, for later use, that the be-a-cube constraint is almost parallel to the objective function contours.\n\nMany organizations use a budget mechanism to manage their affairs. The organization defines divisions or projects, and each of these is given a dollar budget to stay within. The individual division or project manager can arrange things more or less as she thinks best, so long as she stays within the budget. This is a kind of constraint: a budget constraint.\nSuppose you have been tasked to set up a new factory and given a budget of $5,500,000 to do so. You were given this task because you have a particular expertise in how best to set up the factory, but your design will of course depend on the relative prices of the different inputs to the production process.\nFor simplicity, let’s imagine that there are two main inputs: labor \\(L\\) and capital/equipment \\(K\\). It would be silly to spend all the budget on labor and none on capital; the workers would have no tools to work with. Similarly, capital without labor has no productive value. The best design for the factory will be a mix of labor and capital.\nSince the purpose of the factory is to make things for sale, a good objective function will be the sales value of the output produced by the factory. Economists have a favored form for production functions of this sort, a power-law called the Cobb-Douglas function. The essential insight behind the Cobb-Douglas function is that doubling both capital and labor (as if you built a second factory alongside the first) should double production. The Cobb-Douglas form for production as a function of capital and labor is \\[Q(L, K) = p b L^a K^{1-a}\\ .\\] You will use your expertise to set the values of the \\(a\\) and \\(b\\) parameters. The price \\(p\\) of each unit of output will be set by the market: Let’s assume for planning purposes that it is \\(p - \\$450\\) per unit. Suppose you have determined that \\(a=0.3\\) and \\(b=40\\) are appropriate. This production function is shown in Figure 49.14.\n\n\n\n\n\nFigure 49.14: A Cobb-Douglas production function for factory output with \\(p=100\\), \\(b=40\\) and \\(a=0.3\\). (Output units in millions of dollars).\n\n\n\n\nAs you can see from Figure 49.14, the more labor and the more capital you use, the higher the production. Notice that the production function itself does not have an argmax interior to the domain being plotted. It is one of those “more is better” situations.\nSuppose that labor costs $6000 per person-month. Capital, in units of production stations, costs $13,000 per unit. Your budget constraint reflects the total cost of capital and labor: \\(6000 \\cdot L + 15000 \\cdot K \\leq 5500000\\). This constraint is graphed in Figure 49.15.\n\n\n\n\n\nFigure 49.15: The production function for factory output with the budget constraint shown in green.\n\n\n\n\nAny mixture of labor and capital that falls outside the green zone stays within your budget. What’s the best mixture? The one that gives the largest production. You can read this off the graph, \\(L\\approx 650\\) person-months and \\(K\\approx 125\\) workstations which gives slightly more than $7 million dollars in production.\nThe argmax is right on the frontier of the constraint region. Put into more operational terms: You will want to spend your entire budget to maximize production. This is hardly a surprise to anyone who has to work within a budget. Knowing that you’re going to use the whole budget, you might as well have found the argmax by walking along the constraint frontier from left to right. As you start near \\(K=250\\) and \\(L=380\\), the path you walk goes uphill in terms of the production function. The path continues uphill until you reach the argmax. Near the argmax, the path is level. After the path crosses the argmax, it is leading downhill. At the argmax, the production function contours are parallel to the constraint boundary.\nYou might like to think of this in terms of bicycling along a path in hilly terrain. (The hill is shown in Figure 49.15 as the contours, the path is the boundary of the green area, running diagonally from top left to bottom right in the graph.) When you reach the local high point on the path, you may not be at the top of the hill. But you will be on a flat spot on the path, meaning that the path is parallel to the contour of the hill at that point."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#constraint-cost",
    "href": "Manifestations/B4-optimization.html#constraint-cost",
    "title": "49  Optimization and constraint",
    "section": "49.3 Constraint cost",
    "text": "49.3 Constraint cost\nOptimization techniques have an important role to play as aids to human decision making. Let’s see how the mathematical representation of a constraint as a function can facilitate the human decision-making process.\nIn the previous section, the box designer’s request that the box be cubic was translated into an equality constraint, \\(y-3x=0\\), shown as the green line in Figure 49.13. The skilled modeler can bring additional power to the analysis by translating that constraint, \\(y-3x=0\\) into a function, for example\n\\[\\text{Equation:}\\ \\  \\ y - 3x = 0\\ \\ \\longrightarrow\\ \\ \\ \\text{Function:}\\ \\ \\text{cube-box}(x, y) = y / 3x\\ .\\]\nAny \\((x^+, y^+)\\) that produces \\(\\text{cube-box}(x^+, y^+) = 1\\) is a pair that satisfies the constraint. In other words, the equality constraint amounts the 1-contour of the cube_box() function.\nTranslating the constraint into a function provides the opportunity to reframe the situation from the mandate, “the box must be a cube,” into a question, “How cubic-like is the box?” If the value of \\(\\text{cube-box}(x,y) > 1\\), the box is flatter than a cube; something in the direction of a pizza box. If \\(\\text{cube-box}(x,y) < 1\\) the box is taller than a cube, as if flowers were being shipped in it.}\nThe constraint-to-function translated situation is shown in Figure 49.16:\n\n\n\n\n\nFigure 49.16: Zooming in on the objective function Profit() and showing the function version of the constraint, cube_box() using \\(\\color{magenta}{\\text{magenta}}\\) contours, with the heavy green line being the contour at cube_box(x,y)=1.\n\n\n\n\nEarlier, we saw that if restricted to inputs on the contour \\(\\text{cube-box}(x,y) = 1\\), the optimal output value of Profit() is about $13.50. Now we have a broader picture. For instance, suppose we allow a “little” deviation in box shape from a cube, say, cube_box(x,y) = 1.05. If we allowed this, the value of the Profit() function could be increased from $13.50 to about $22.50 .\nWhether the $9 increase in value justifies the deviation from a cube by 5% is a matter of judgement. We don’t have an immediate way to translate the output of cube_box() into the same units as the output of profit(). The two different units are said to be incommensurate, meaning that they cannot be directly compared. Nonetheless, we now have a basis for a conversation. It might go like this:\nModeler to Designer: I realize that from your perspective, a cube is the optimal shape for the box.\nDesigner: Right. Cubes are in fashion this year. Last year it was the Golden Ratio.\nModeler: It might sound surprising, but we find that so long as you are close to the optimal, it does not much matter if you are exactly on it. How close to a perfect cube would be good enough?\nDesigner: What’s really important is that the box be perceived as a cube in our sales material. I think that most customers would think “cube” so long as the edge lengths are within about 15% of one another.\nModeler: That’s very helpful. Let’s see if I can translate that into the cube_box() function.\n[Modeler does some scribbling while mumbling to himself. “\\(y-2x\\) is the base width and depth of the box, and \\(x\\) is the height of the box. So if \\(y-2x = 1.15 x\\) then \\(y = 3.15 x\\). \\(\\text{cube-box}(x, 3.15 x) = 1.05\\).]\nModeler: [to Designer] The 15% deviation corresponds to an output of 1.05 from \\(\\text{cube-box}()\\).\nModeler: [To product manager] Making that change in shape increases profit per box from $13.50 to $22.50.\nProduct manager: Good job! How about a 30% deviation? That let’s us get up to about $33 in profit.\nDesigner: But it would make the box shaped like a brick! Bricks are so 1990s!\nModeler: It sounds like a 15% deviation would be about right.\nMaking the constraint negotiable by representing it with a function, broadens the scope of the discussion and points to new ways of improving the result.\n\nLet’s return to a previous example about determining optimal levels of labor and capital in a factory. In that example, the objective function was the money value of the product produced. There was also a budget constraint. Translating the budget constraint into a function, which we will call expenditure(K, L), we have \\(\\text{expenditure}(K, L) = 6000 L + 13000 K\\). Our budget amounts to enforcing \\(\\text{expenditure}(K, L) = \\$5,500,000\\).\nA manager presented with a budget knows that she should work within the constraints of that budget. Mathematically, however, it is easy to imagine the budget being changed, either relaxed or tightened. This mathematical possibility provides the means to extract new information that can be helpful in making decisions at a higher level, that is, above the rank of the manager. This can be helpful to higher management—the people who are responsible for seeing the bigger picture.\nFigure 49.17 show the production function plotted along with the expenditure function. The budget constraint corresponds to a single output level of the expenditure function, that is, a single contour of the expenditure function. Other contours correspond to different values for the budget constraints. Such a graph makes it easy to calculate the consequences for relaxing (or tightening) the constraint.\n\n\n\n\n\nFigure 49.17: The production function for factory output (blue, curved lines) and the labor/capital expenditure function (magenta, straight lines). Contour labels are in millions of dollars. Contour levels for expenditure (magenta: 3.1, 3.9, 4.6, etc.) were selected so that the magenta contours are nearly tangent to the blue factory-output contours. This makes it easy to see the K/L position for optimal factory output for each of the indicated expenditure levels.\n\n\n\n\nWith the budget fixed at $5.5 million—that is, on the $5.5-million contour of the expenditure function—the maximum production was $7.1 million.\nWhat happens if we pretend that the budget level was different? Doing so is a matter of looking at a different contour of the expenditure function. For example, if the budget had been smaller, say only $5 million, then production also goes down, to $6.5 million. On the other hand, if we had the means to increase the budget to $6 million, production would go up to $7.7 million.\nIn this example we see that an increase in budget of $500K produces an increase in production worth $600K. It might seem logical that it is worth raising the budget to harvest the extra production, but that is not necessarily the case. To see why, recall that we use constraints such as the budget constraint in this problem to represent a real-world situation where there are multiple objectives, not just the particular objective represented by the objective function. There is a budget in the first place because there are other, competing uses for the money. For instance, the money might be better spent in some other product line that is even more profitable. Or perhaps higher management, taking a long-term strategic view, would prefer to spend the funds on research and development.\nThe point of exploring theoretical changes in the budget is to provide information to the higher-level decision makers, the people who set the budget as opposed to the managers who have to work within the budget. The format that most non-technical people would find accessible is simple: a $500K increase in the budget will result in $600K greater production.\nIn mathematical presentations, this same information is often formatted differently, as a ratio called the Lagrange multiplier. The Lagrange multiplier in this example would be 600/500, that is, 1.2. There is no intrinsic advantage of the Lagrange multiplier format over the common sense format, but the Lagrange multiplier is the format used in many textbooks, so it is worthwhile to know the nomenclature. Some economists have a more evocative name for the ratio: the shadow price of the constraint. Thus, the theoretical exploration of relaxing the constraint provides a straightforward way to put a cost on the constraint. This gives a reasonable way to determine the value of something when there is no direct market for it.\nAn important example of a shadow price comes in the setting of life-saving interventions. For example, increasing spending on highway safety can save lives. If $7.5 billion in increased expenditures saves 1000 lives, the shadow price is $7.5 M per life. People who misinterpret the constraint-to-function methodology often think that it is about cravenly putting a money value on life. In reality, the method merely reveals the money value on life implicit in decisions such as budget allocations. Knowing that the shadow price is $7.5 M does not say what the value of life should be. But it provides a mechanism for comparing different uses for the money. For instance, if the shadow price for increased regulation of toxic industrial chemicals is $11.3 M per life, the relative shadow prices provide an indication that budget money might reasonably be shifted from chemical regulation to highway safety. Economists and epidemiologists who undertake such calculations reveal that the mixture of spending on different life-preserving interventions is far from optimal.\n\n\nGenerations of calculus students have been taught a method of mathematical optimization in the presence of constraints that involves positing a Lagrange multiplier, typically written as \\(\\lambda\\), and carrying out a series of differentiations followed by equation solving to find an argmax, which simultaneously provides a numerical value for \\(\\lambda\\). It is easier to understand the motivation behind this by considering the gradient of the objective function and the gradient of the constraint function. If the goal is, say, to maximize production and simultaneously minimize expenditures, we would want to walk up the production gradient and down the expenditure gradient.\nFigure 49.18 shows two gradient fields, one for the production function in the factory-design example and one for expenditure. (The negative of the expenditure gradient is shown, since the goal is to keep expenditures small.)\n\n\n\n\n\nFigure 49.18: The production and expenditure functions displayed as gradient fields. Expenditure is brown, production is magenta.\n\n\n\n\nAt each point in the graphics frame, the two gradient vectors form an angle. For example, near the point labeled (a) the angle is roughly 140 degrees, while near (b) the angle is 180 degrees.\nAny value of \\(K\\) and \\(L\\) where the angle is less than 180 degrees is sub-optimal or dominated by some other choice of \\(K\\) and \\(L\\). For instance, near label (a), you could improve both production and expenditures by moving to the southeast. When the angle is 180 degrees, the objective and constraint functions are in complete opposition to one another; any movement in favor of one comes at the cost in the other."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#note-other-optimization-algorithms",
    "href": "Manifestations/B4-optimization.html#note-other-optimization-algorithms",
    "title": "49  Optimization and constraint",
    "section": "49.4 Note: Other optimization algorithms",
    "text": "49.4 Note: Other optimization algorithms\nContemporary work often involves problems with tens, hundreds, thousands, or even millions of inputs. Even in such large problems, the mechanics of finding the corresponding gradient vector are straightforward. Searching through a high-dimensional space, however, is not generally a task that can be accomplished using calculus tools. Instead, starting in the 1940s, great creativity has been applied to develop algorithms with names like linear programming, quadratic programming, dynamic programming, etc. many of which are based on ideas from linear algebra such as the qr.solve() algorithm that you will meet in Block 5, or ideas from statistics and statistical physics that incorporate randomness as an essential component. An entire field, operations research, focuses on setting up and solving such problems. Building appropriate algorithms requires deep understanding of several areas of mathematics. But using the methods is mainly a matter of knowing how to set up the problem and communicate the objective function, constraints, etc. to a computer.\nPurely as an example, let’s examine the operation of an early algorithmic optimization method: Nelder-Mead, dating from the mid-1960s. (There are better, faster methods now, but they are harder to understand.)\nNelder-Mead is designed to search for maxima of objective functions with \\(n\\) inputs. The video shows an example with \\(n=2\\) in the domain of a contour plot of the objective function. Of course, you can simply scan the contour plot by eye to find the maxima and minima. The point here is to demonstrate the Nelder-Mead algorithm.\nStart by selecting \\(n+1\\) points on the domain that are not colinear. When \\(n=2\\), the \\(2+1\\) points are the vertices of a triangle. The set of points defines a simplex, which you can think of as a region of the domain that can be fenced off by connecting the vertices.\nEvaluate the objective function at the vertices of the simplex. One of the vertices will have the lowest score for the output of the objective. From that vertex, project a line through the midpoint of the fence segment defined by the other \\(n\\) vertices. In the video, this is drawn using dashes. Then try a handful of points along that line, indicated by the colored dots in the video. One of these will have a higher score for the objective function than the vertex used to define the line. Replace that vertex with the new, higher-scoring point. Now you have another simplex and can repeat the process. The actual algorithm has additional rules to handle special cases, but the gist of the algorithm is simple."
  },
  {
    "objectID": "Manifestations/B4-optimization.html#exercises",
    "href": "Manifestations/B4-optimization.html#exercises",
    "title": "49  Optimization and constraint",
    "section": "49.5 Exercises",
    "text": "49.5 Exercises\nProblem with Manifestations Exercises/ape-choose-closet.Rmd\nProblem with Manifestations Exercises/ape-choose-closet2.Rmd\nProblem with Manifestations Exercises/rat-find-magnet.Rmd\n\nExercise 50.06\nHere is the gradient field of an objective function.\n\n\n\n\n\n\n\n\n\nWhere is the argmax?\nProblem with Manifestations Exercises/panda-go-kayak.Rmd\nProblem with Manifestations Exercises/panda-go-kayak2.Rmd\n\n\nExercise 50.14\nBased on an extensive but fictive observation of activity and grades of college students, the model shown in the figure was constructed to give GPA as a function of the number of hours each weekday (Monday-Friday) spent studying and spent in social activity and play. (Activity during the weekend was not monitored.)\n\n\n\n\n\n\n\n\n\nSeveral points in the graphic frame have been marked with red letters. Refer to these letters when answering the following questions.\n\n\nPart A According to the model, what’s the optimal combination of Study and Play to achieve a high GPA?\nF G H I\n\n\n\n\nPart B Which of these letters marks a place on the graph where the partial derivative of GPA with respect to Play is positive?\nB C K L\n\n\n\n\nPart C Which if these ketters marks a place on the graph where the partial derivative of GPA with respect to Play is negative.\nA F H K\n\n\n\n\nPart D Where is the partial derivative with respect to Study is negative?\n\nNowhere. \\(\\partial_{study} GPA()\\) is always positive. More study = better grades.\nE\nF\nL\n\n\n\n\n\nPart E Study and Play are not the only activities possible. Sleep is important, too, as are meals, personal care, etc. In the study, students were observed who spent up to 22 hours per day in Study or Play. Presumably, such students crashed on the weekend.\nSuppose you decide to budget 12 hours each weekday day in activities other than Study and Play. Which letter labels the constrained optimal mix (argmax) of Study and Play.\nE I K L\n\n\n\n\nPart F What is the “shadow price” of GPA with respect to the budget for a budget constraint of 12 hours? Give both an estimated numerical value as well as units.\n\n-0.8 hour/gradepoints\n0.3 gradepoints/hour\n+0.9 gradepoints/hour\n+1.3 hour/gradepoints\n\n\n\n\n\nPart G Consider a student who budgets 22 hours per day for Study and Play. Which letter is closest to the constrained argmax with a 22-hour constraint?\nA B C D\n\n\n\n\nPart H What is the “shadow price” of GPA with respect to the budget constraint of 22 hours? Give the estimated numerical value.\n\n-0.5 gradepoints/hour\n0 gradepoints/hour\n+0.5 gradepoints/hour\n+1.0 gradepoints/hour\n\n\n\n\n\nPart I Based on the shadow price from the previous question, which of these is the best advice to give the student (who seeks to maximize GPA)?\n\nYou’re hopeless. There aren’t enough hours in the day for you to get a good GPA.\nYou’ve got to squeeze out more effort studying. Give it your all!\nPlay more, study less!\nStudy less\nStudy less, play less. Sleep!\n\n\n\n\n\n\n\n\nExercise 50.18\nIn this exercise, you will work with an optimization problem. First, we will ask about a mathematical solution to the problem. Next, we will show that the mathematical solution is not necessarily the best real-world solution because of multiple objectives in decision making. Then we will show you a real-world decision-making rubric that is widely accepted, at least among people who listen to the whole story with an open mind.\nThe graph shows the estimated number of lives saved by three different health-care related interventions – A, B, C – as a function of the amount of money spent on each.\n\n\n\n\n\n\n\n\n\nYou have $1,000,000,000 to spend altogether on these interventions. Your policy alternatives are all the different combinations of spending on (A), (B), and (C) that add up to $1B (or less).\nHow should you split up the money among the interventions? For example, we could spend $125M on B, $125M on C, and $750M on A. This would save an estimated 346 lives. Can we do better?\nImagine that we use \\(x\\), \\(y\\) and \\(z\\) to denote expenditure, with \\(x\\) spent on intervention A, \\(y\\) on intervention B, and \\(z\\) on intervention C. Altogether, the budget is \\(x + y + z = \\$1B\\).\n\n\nPart A Suppose \\(x = 750\\), \\(y = 125\\), and \\(z=125\\), where units are millions of dollars. It is suggested that reducing \\(x\\) by $1M to increase \\(z\\) by that amount will produce a better outcome in terms of the total number of lives saved. That is, move some money from intervention A to intervention C. Is this suggestion correct? Why or why not?\n\nNot correct. The number of lives saved by spending $750M on A is larger than the number that would be saved by spending that much on B or C.\nNot correct. We will want to move the money to B instead.\nCorrect. The derivative \\(\\partial_x A(x)\\) at \\(x=750\\) is smaller than the derivative \\(\\partial_z C(z)\\) at \\(z=125\\).\nCorrect. We should spend equally on all three interventions. That is, set \\(x = y = z = 333.33....\\)\n\n\n\nA general principle is this: If spending a little more on one intervention increases the output more than the loss due to spending less on another intervention, the shift in funding is worthwhile.\n\n\nPart B If you follow the above logic, you will continue to move money from A to C until it is no longer beneficial to do so. What will be the maximum amount of spending on A makes it not worthwhile to move additional money from A to C? (Choose the closest answer.)\n$ 250M $ 375M $ 500M $ 625M\n\n\n\n\nPart C Imagine that you have moved all the money from A to C that it is worthwhile to do . Which of these statements is true at those values \\(x_0\\), \\(z_0\\)?\n\n\\(\\partial_x A(x_0) = \\partial_z C(z_0)\\)\n\\(A(x_0) = C(z_0)\\)\n\\(C(x_0) = A(z_0)\\)\n\\(\\partial_x A(x_0) = 0\\) and \\(\\partial_z C(z_0) = 0\\).\n\n\n\nWe found it worthwhile to move expenditure from A to C to optimize the sum of their outputs and are operating at about \\(x_0 = \\$500M\\) and \\(z_0 = \\$375M\\), leaving \\(y=\\$125M\\) to spend on intervention B. Is it worthwhile to move money from A or C to B or vice versa? But first, a simpler question.\n\n\nPart D If we were going to move a small amount of money from A or C into B, would it be better to take the money from A or from C? Why?\n\nTake it from A, since we are spending far more on A than C.\nTake it from C, since we are already spending far less on C than on A.\nTake it from C. The slope \\(\\partial_z C(z_0)\\) compared to \\(\\partial_x A(z_0)\\) is such that a small reduction on spending on C has less impact than a small reduction in spending on A.\nTake it from A. The slope \\(\\partial_z C(z_0)\\) compared to \\(\\partial_x A(z_0)\\) is such that a small reduction on spending on A has less impact than a small reduction in spending on C.\n\n\n\n\n\nPart E Right now in our process, we are planning to spend $125M on B. Is it worthwhile to move money from C to B?\n\nNo, the output of B larger than the output of C at $125M.\nYes, move most of the money from C to B.\nYes, but only move a little money from C to B.\nNo, move money from B to C.\n\n\n\n\n\nPart F At the optimal amount of money \\(y^\\star\\) spent on B and \\(z^\\star\\) spent on C, which of these is true about the slopes \\(\\partial_y B(y^\\star)\\) and \\(\\partial_z C(z^\\star)\\)?\n\nThere is not any fixed relationship. They are what they are.\nThe two slopes are equal.\nThe slope of B is greater than the slope of C.\nThe slope of C is greater than the slope of B.\n\n\n\n\n\nPart G Is it more proper to say the “slope \\(\\partial_z C(z^\\star)\\)” rather than the “derivative \\(\\partial_z C(z^\\star)\\)?” (This is a general review problem for the course, not something specifically about optimization.)\n\nYes. A derivative is a function while a slope is a quantity.\nNo. Slope and derivative are the same thing.\nYes. “Derivative” sounds fancier than “slope”.\nNo. Slopes measure steepness from right to left, while derivatives give steepness from left to right.\n\n\n\nBackground: The graphs are fictitious, but let’s pretend they are:\n\nA Surgical treatment of congenital heart defects in newborns.\nB Treatment for hemophilia.\nC Memory-care for people with Alzheimers.\n\nNotice that the people being affected are in different, non-overlapping groups. So moving funding from one group to another is effectively “robbing Peter to pay Paul.” If you, as a decision maker inherited a situation where \\(x = \\$750M\\), \\(y=\\$125M\\), and \\(z=\\$125M\\), changing the expenditures would make one group better off (no matter how you did it!) and would make another group worse off. And imagine the headlines if you moved money from A to C or B: “Government slashes funding for newborns!”. Or perhaps an editorial: “We need to find a way to increase funding for hemophilia without cutting other life-saving spending.” This raises an important question: Is it ever worthwhile to forgo spending to save lives? How would anyone decide which lives are worth saving? Most people are uncomfortable with such questions. Yet the decisions taken by leaders, whatever they be, inevitably have a mathematically equivalent formulation which translates to the value of life.\nProbably, most people would decline to make a decision comparing two lives, for instance, saving a 10-year old versus saving a 90-year old. But it is not always possible to escape such trade-offs and the people who need to take the decision need guidance about what to do. In an open society, we expect such decisions to be backed by good rationale and so we have to develop means for distinguishing between better and worse rationales.\nOne example comes from epidemiology and the concept of a “quality-adjusted life year” (QALY). A QALY is a measure of duration of life adjusted for the health condition of the person — a year of a person in good health is 1 QALY, but a year in a person in very poor health is less than 1 QALY.\nQALYs do not solve the problem of optimizing health-related outcomes. They are an imperfect means of dealing with an impossible problem. Sometimes that is the best we can do.\nProblem with Manifestations Exercises/crow-trim-laundry.Rmd"
  },
  {
    "objectID": "Manifestations/B4-probability.html",
    "href": "Manifestations/B4-probability.html",
    "title": "50  Probability and evidence",
    "section": "",
    "text": "We often deal with situations of uncertainty, situations where only partial predictions are possible. For instance, we can say whether a person may be at high risk for a disease, say, diabetes or lung cancer. But this does not let us predict with certainty whether the person will get the disease. Instead, the term “high risk” indicates that we know something but not everything about the situation: not whether or not the person will get the disease but whether they are “likely” to have or to get it. Another example: a car might be said to be “unreliable.” We do not mean by this that the car cannot be used. Rather we are thinking that from time to time the car might fail to start or run. A car where this happens once over a few year span is reliable, a car where this happens on a month-to-month basis is not reliable.\nYou may well have had some textbook exposure to probability as an intellectual field. Typical examples used to illustrate concepts and methods are coins being flipped, dice being tossed, and spinners spun. Colored balls are drawn from urns, slips of paper from hats, and so on. Each of these is a physical representation of an idealized mechanism where we feel sure we understand how likely each possible outcome is to happen.\nIn this chapter, we will use two basic imagined settings where uncertainty comes into play: the risk of disease before the disease is diagnosed and the safety of a self-driving car as it comes out of the factory. The word “imagined” signals that you should not draw conclusions about the facts of any particular disease or any particular self-driving car; we are merely using the imagined settings to lay out concepts and methods for the mathematical presentation and analysis of uncertainty and risk. Of particular importance will be the mathematical means by which we represent our knowledge or belief in these settings and the way we can properly update our knowledge/belief as new information becomes available."
  },
  {
    "objectID": "Manifestations/B4-probability.html#probability-density",
    "href": "Manifestations/B4-probability.html#probability-density",
    "title": "50  Probability and evidence",
    "section": "50.1 Probability density",
    "text": "50.1 Probability density\nA probability, as you may know, is a dimensionless number between zero and one (inclusive). In this chapter, you will be dealing with functions relating to probabilities. The input to these functions will usually be a quantity that can have dimension, for instance, miles driven by a car. For some of the functions we will see in this chapter, the output will be a probability. For other functions in this chapter, the output will be a probability density.\nProbability relates to the abstract notion of an event. An event is a process that produces an outcome. For instance:\n\nFlipping a coin is an event where the possible outcomes of H and T.\nTaking a medical screening test is an event where the outcomes are “positive” or “negative.”\nThrowing a dart at a bullseye is an event where the outcome is the distance of the impact point from the center of the bullseye.\n\nAn event with a discrete outcome—coin flip, medical screening test—can be modeled by assigning a probability number to each of the possible outcomes. To be a valid probability model, each of those assigned numbers should be greater than or equal to zero. In addition, the sum of the assigned numbers across all the possible outcomes should be 1.\nFor events with a continuous outcome, such as the dart toss where the outcome is distance from the center, the probability model takes the form of a function whose domain is the possible outcomes. For the model to be a valid probability model, we require that the function output should never be less than zero. There is another requirement as well: the integral of the function over the entire domain should be 1. For the dart-toss event, if we denote the distance from the bullseye as \\(r\\) and the assigned number for the probability model as \\(g(r)\\), the integral requirement amounts to \\[\\int_0^\\infty g(r) dr = 1\\ .\\]\nNote that the output \\(g(r)\\) is not a probability, it is a probability density. To see why, let’s use the fundamental theorem of calculus to break up the integral into three segments:\n\nclose to the bullseye: \\(0 \\leq r \\leq a\\)\nfar from the bullseye: \\(b < r\\)\nnot close but not far: \\(a < r \\leq b\\)\n\nThe total integral is \\[\\int_0^\\infty g(r) dr = 1\\ = \\int_0^a g(r) dr + \\int_a^b g(r) dr + \\int_b^\\infty g(r) dr.\\] The probability that the dart lands at a distance somewhere between \\(a\\) and \\(b\\) is \\[\\int_a^b g(r) dr\\ .\\] Since \\(r\\) is a distance, the dimension \\([r] =\\ \\)L. Suppose the units of \\(r\\) are centimeters. We need \\(\\int g(r) dr\\) to be a dimensionless number. Since the dimension of the integral is \\([r] \\cdot [g(r)] = [1]\\), it must be that \\([g(r)] = [1/r] = \\text{L}^{-1}\\). Thus, \\(g(r)\\) is not a probability simply because it is not dimensionless. Instead, in the dart example, it is a “probability-per-centimeter.” This kind of quantity—probability per something—is called a probability density and \\(g(r)\\) itself is a probability density function.\nTo show the aptness of the word “density,” let’s switch to a graphic of a function that uses literal density of ink as the indicator of the function value. Figure 50.1) shows what the dart toss’s \\(g(r)\\) probability density function might look like:\n\n\n\n\n\nFigure 50.1: Showing a probability density function for the dart distance in two modes: 1) an ordinary function graph and 2) the density of ink.\n\n\n\n\n\nConsider a simple competition of the sort you might encounter at a fund-raising fair. There is a jar on display, filled with coins that have been donated by one of the fair’s sponsors. You pay $1 (which goes to a good cause) to enter the contest. Your play is to describe how much money is in the jar, writing your description down along with your name on an entry form. At the end of the day, an official will open the jar, count the money, and announce who made the best estimate. The winner gets the money in the jar.\n\n\n\n\n\n\n\n\n\nIn the usual way these contests are run, the contestants each write down a guess for the amount they think is in the jar, say $18.63. The winner is determined by seeing whose guess was closest to the actual value of the coins in the jar.\nIn reality, hardly anyone believes they can estimate the amount in the jar to the nearest penny. The person guessing $18.63 might prefer to be able to say, “between 18 and 19 dollars.” Or, maybe “$18 \\(\\pm\\) 3.” To communicate what you know about the situation, it is best to express a range of possibilities that you think likely.\nIn our more mathematical contest, we ask the participants to specify a function that describes their beliefs about the money in the jar. The instructions state, “On the graph-paper axes below, sketch a continuous function expressing your best belief about how much money is in the jar. The only requirement is that the function value must be zero or greater for all inputs.”\n\n\n\n\n\n\nFigure 50.2: The entry form for the money-in-the-jar contest.\n\n\n\nTake a minute to look at the picture of the jar and draw your function on the axes shown above. Think about why the contest form appropriately does not ask you to scale the vertical axis.\nHere are contest entries from three competitors.\n\n\n\n\n\nFigure 50.3: Three contestants’ contest entries.\n\n\n\n\n\nThe functions called for by the contest instructions are relative density functions. The “relative” means that the function indicates where the probability is more or less dense, but the function has not yet been scaled to be a probability density function. Suppose \\(h(x)\\) is a relative density function such that\n\\[\\int_{-\\infty}^\\infty h(x)\\, dx = A \\neq 1\\ .\\] Although \\(h(x)\\) is not a probability density function, the very closely related function \\(\\frac{1}{A} h(x)\\) will be a probability density function. We will use the term normalizing to refer to the simple process of turning a relative density function into a probability density function.\nA relative density function is entirely adequate for describing the distribution of probability. However, when comparing two or more probability distributions, it is important that they all be on the same scale. Normalizing the relative density functions to probability density functions accomplishes this. Figure 50.4 compares the three relative probability functions in Figure 50.3. Johnny makes the density large over a narrow domain and zero elsewhere, while Louisa specifies a small density over a large domain. All three competitors’ functions have an area-under-the-curve of dimensionless 1.\n\n\n\n\n\nFigure 50.4: Comparing the contest entries by normalizing each of them to a probability density function."
  },
  {
    "objectID": "Manifestations/B4-probability.html#three-density-functions",
    "href": "Manifestations/B4-probability.html#three-density-functions",
    "title": "50  Probability and evidence",
    "section": "50.2 Three density functions",
    "text": "50.2 Three density functions\nThree commonly used families of probability density functions are:\n\nthe gaussian density function\nthe exponential density function\nthe uniform density function.\n\nFigure 50.5 shows their shapes.\n\n\n\n\n\n\n\n(a) Uniform density\n\n\n\n\n\n\n\n(b) Gaussian density\n\n\n\n\n\n\n\n(c) Exponential density\n\n\n\n\nFigure 50.5: Three probability density functions that are often used in applied work.\n\n\nThe uniform density function, \\(u(x, a, b)\\) is more or less the equivalent of the constant function. The family has two parameters \\(a\\) and \\(b\\) with the function defined as:\n\\[\\text{unif}(x, a, b) \\equiv \\left\\{\\begin{array}{cl}\\frac{1}{b-a} & \\text{for}\\ a \\leq x \\leq b\\\\0& \\text{otherwise} \\end{array}\\right.\\]\nThis function is used to express the idea of “equally likely to be any value in the range \\([a, b]\\).” For instance, to describe a probability that a January event is equally likely to occur at any point in the month, you can use \\(u(x, 0, 31)\\) where \\(x\\) and the parameters \\(a\\) and \\(b\\) have dimension T and are in units of days. Notice that the density itself has dimension T-1 and units “per day.”\nThe gaussian density function, \\(\\dnorm(x, \\text{mean}, \\text{sd})\\) is familiar to you from previous blocks in this book: the bell-shaped function. It is known also as the normal distribution because it is so frequently encountered in practice. It is a way of expressing, “The outcome of the event will likely be close to this particular value.” The parameter named mean specifies “this particular value.” The parameter sd specifies what’s mean by “close.” The gaussian density function is smooth. It is never zero, but \\(\\lim_{x \\rightarrow \\pm \\infty} \\dnorm(x, \\text{mean}, \\text{sd}) = 0\\).\nTo use an analogy between physical density (e.g., kg per cubic-meter), where density times size gives mass, we can say that the total mass of a probability density function is always 1. For the gaussian density, 68% of of the total mass is within \\(\\pm 1\\)sd of the mean, 95% is within \\(\\pm 2\\)sd of the mean, 99.7% within \\(\\pm 3\\)sd, and 99.99% within \\(\\pm 4\\)sd.\nThe exponential probability density is shaped just like an exponential function \\(e^{-kx}\\). It is used to describe events that are equally likely to happen in any interval of the input quantity, and describes the relative probability that the first event to occur will be at \\(x\\)."
  },
  {
    "objectID": "Manifestations/B4-probability.html#sec-expected_value",
    "href": "Manifestations/B4-probability.html#sec-expected_value",
    "title": "50  Probability and evidence",
    "section": "50.3 Expectation value, mean and variance",
    "text": "50.3 Expectation value, mean and variance\nProbability theory was originally motivated by problems in gambling, specifically, figuring out what casino games are worth betting on. A feature of casino games—roulette, slot machines, blackjack, Texas hold’em, etc.—is that they are played over and over again. In any one round of play, you might win or you might lose, that is, your “earnings” might be positive or they might be negative. Over many plays, however, the wins and loses tend to cancel out. One way to summarize the game itself, as opposed to the outcome of any single play, is by the average earnings per play. This is called the expected value of the game.\nThis logic is often applied to summarizing a probability density function. If \\(x\\) is the outcome of the random event described by a probability density \\(f(x)\\), the expected value of the probability density is defined as\n\\[\\mathbb{E}\\!\\left[{\\strut} x\\right] \\equiv \\int_{-\\infty}^\\infty x\\, f(x) \\, dx\\ .\\]\nIn Section Section 52.4, we will see this same form of integral for computing the center of mass of an object.\n\nWhy are you using square braces \\(\\left[\\strut\\ \\ \\right]\\) rather than parentheses \\(\\left(\\strut \\ \\  \\right)\\).\nWe always used parentheses to indicate that the enclosed quantity is the input to a function. But \\(\\mathbb{E}\\!\\left[{\\strut} x\\right]\\) is not a function, let alone a function of \\(x\\). Instead, \\(\\mathbb{E}\\!\\left[{\\strut} x\\right]\\) is a numerical summary of a probability density function \\(f(x)\\).\n\n\nFind the expected value of the gaussian probability density \\(\\dnorm(x, \\text{mean}=6.3, \\text{sd}= 17.5)\\). Using the R/mosaic Integrate() function, we have ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIntegrate(x * dnorm(x, 6.3, 17.5) ~ x, bounds(x=-Inf:Inf))\n## [1] 6.3\n\nThe expected value of a gaussian is the same as the parameter called mean which describes the argmax of the gaussian. :::\nAnother important quantity to describe data or probability distributions is the variance, which is the average of the square distance from the mean. In math notation, this looks like\n\\[\\mathbb{E}\\!\\left[{\\large\\strut} (x - \\mathbb{E}[x])^2\\right] = \\int_{-\\infty}^{\\infty} \\left(\\strut x - \\text{mean}\\right)^2\\, \\dnorm(x, \\text{mean}, \\text{sd})\\, dx\\ .\\]\n\nCompute the variance of a gaussian probability density \\(\\dnorm(x, \\text{mean}=6.3, \\text{sd}= 17.5)\\).\nTo do this, we must first know the mean, then we can carry out the integration. ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIntegrate((x-6.3)^2 * dnorm(x, mean=6.3, sd=17.5) ~ x, bounds(x=-Inf:Inf))\n## [1] 306.25\n\nAgain, you might have anticipated this result, since the variance is the square of the standard deviation (sd) and we were using a particular gaussian distribution with sd equaling 17.5. Of course, \\(17.5^2 = 306.25\\). :::\nTo illustrate the calculations in another setting, we will use an exponential probability function. Just as the R function dnorm() gives the density of the “normal”/gaussian distribution, the R function dexp() outputs the density of the exponential distribution. We used \\(k\\) as the parameter in the exponential distribution. In R, the parameter is framed in terms of the rate at which events happen, that is, the expected number of events per unit time. For instance, the following integrals compute the mean and standard deviation of an exponential process where events happen on average twice per time unit.\n\nIntegrate(x * dexp(x, rate=2) ~ x, bounds(x=0:Inf))\n## [1] 0.5\n\nThe result shouldn’t surprise you. If events are occurring on average twice per unit time, the average time between events should be 0.5 time units.\nHere’s the variance of the same distribution ::: {.cell layout-align=“center” fig.showtext=‘false’}\nIntegrate((x-0.5)^2 * dexp(x, rate=2) ~ x, bounds(x=0:Inf))\n## [1] 0.25\n::: It works out that for an exponential distribution with parameter \\(k\\), the mean is \\(1/k\\) and the standard deviation (square root of the variance) is also \\(1/k\\).\nFinally, let’s look at the mean and variance of a uniform distribution with, say, \\(a=0\\) and \\(b=10\\). We can do this symbolically or numerically. For the mean:\n\\[\\int_{-\\infty}^\\infty x\\  \\text{unif}(x, 0, 10)\\, dx = \\int_0^{10} \\frac{x}{10-0}\\, dx = \\left.{\\Large\\strut} \\frac{x^2}{20}\\right|_{x=0}^{10} \\\\= \\frac{100}{20} - \\frac{0}{20} = 5\\]\nFor the variance, \\[\\begin{eqnarray}\n\\ \\ \\ & \\!\\!\\!\\!\\!\\!\\int_{-\\infty}^\\infty (x-5)^2\\  \\text{unif}(x, 0, 10)\\, dx\\\\\n& = \\int_0^{10} \\frac{(x-5)^2}{10-0}\\, dx\\\\\n& = \\left.{\\Large\\strut}\\frac{(x-5)^3}{30}\\right|_{x=0}^{10}\\\\\n& =\\frac{5^3}{30} - \\frac{(-5)^3}{30} = \\frac{125}{30} - \\frac{-125}{30} = 8 \\tiny{\\frac{1}{3}}\n\\end{eqnarray}\\]\nOr, numerically1\n\nIntegrate(x * dunif(x, 0, 10) ~ x, bounds(x=0:Inf))\n## [1] 5.000001\nIntegrate((x-5)^2 * dunif(x, 0, 10) ~ x, bounds(x=0:Inf))\n## [1] 8.333336"
  },
  {
    "objectID": "Manifestations/B4-probability.html#likelihood-and-data",
    "href": "Manifestations/B4-probability.html#likelihood-and-data",
    "title": "50  Probability and evidence",
    "section": "50.4 Likelihood and data",
    "text": "50.4 Likelihood and data\nIn this section, we will examine the accepted technique for combining data with probability density functions to combine previous knowledge with new observations. The technique, called Bayesian inference, is used throughout science and engineering.\nRecall that a relative density function is a format to describe the relatively likeliness of possible outcomes from a random event. The domain for a relative density function is the complete set of possible outcomes from the event. An example: The distance of a dart’s impact from the bullseye.\nThe output of a relative density function is a non-negative number. For an expert dart thrower, the relative density will be high for small distances and low for large distances. This is just a way of quantifying that the expert’s is likely to hit close to the bullseye.\nIn comparing two relative density functions, for instance the function for an expert dart thrower versus that for an amateur, it is helpful to normalize them so that the integral of the relative density over the entire domain is dimensionless 1. The normalized version of a relative density function is called a probability density functions. Note that the probability density function contains the same information as the relative density function.\nIn this section, we introduce a new type of function that is important in probability calculations involving data. This new type of function is, perhaps confusingly, called a likelihood function.\nLikelihood functions always involve hypothetical reasoning. The idea is to construct a model world whose characteristics are exactly known. In that world, we can imagine constructing a function that gives the probability or probability density of any possible value of a measurement.\nFor instance, Johnny, Louisa, and Geoff each created hypothetical worlds that describe the amount of money in the jar. For each contestant, their personal hypothesis states a probability density over all the theoretically possible amounts of money in the jar.\nThe domain of a likelihood function is all the competing hypotheses. Take a moment to digest that. The domain of money-in-jar likelihood function is not the amount of money in the jar, it is instead the three hypotheses: Johnny’s, Louisa’s, and Geoff’s.\nIt is conventional to denote name a likelihood function \\({\\cal L}()\\). For the competition, a likelihood function will be \\({\\cal L}(\\text{contestant})\\), where \\(\\text{contestant}\\) will be one of “Johnny” or “Louisa” or “Geoff” in our example.\nThere are many likelihood functions that might be relevant to the money-in-jar situation. There is one likelihood function for each possible amount of money in the jar. For instance, \\({\\cal L}_{\\$10}(\\text{contestant})\\) is relevant if there were ten dollars in the jar. Another likelihood function \\({\\cal L}_{\\$11.50}(\\text{contestant})\\) would be relevant if there were eleven dollars and fifty cents in the jar.\nThis notation of naming functions using a subscript can get awkward when there are a huge number of functions. For instance, for the money-in-jar contest there will be a likelihood function for $0.01, $0.02, $0.03, and all other possibilities such as $21.83 or \\(47.06\\). If we want to be able to refer to the whole set of likelihood functions, better to replace the dollar amount in the subscript with a symbol, say \\(m\\) for money. Then the whole set of likelihood functions potentially relevant to the contest would be written \\({\\cal L}_m(\\text{contestant})\\).\n\nThere is another style for notation that you may encounter in your future work. In the alternative style, for example, instead of \\({\\cal L}_m(\\text{contestant})\\) the likelihood function would be written \\({\\cal L}(\\text{contestant}\\, {\\mathbf |} m )\\). The vertical bar is pronounced “given” and is part of a notational system often used in probability calculations.\n\nSince the output of any likelihood function is a probability or a probability density depending on context, we know that the output will be a non-negative quantity.\nLikelihood functions provide the link between data and hypotheses. The idea is that when data become available, it is possible to choose the relevant likelihood function.\nTo illustrate, let’s return to the jar-of-money contest and the three competitors’ entries as shown in Figure 50.4. For convenience, that Figure is reproduced here:\n\n\n\n\n\nFigure 50.6: The contest entries shown in Figure 50.4.\n\n\n\n\nThe functions shown in the Figure are not likelihood functions. But we can use them to construct whatever likelihood function turns out to be relevant in the money-in-jar contest.\n\nIt is time to calculate who won the jar-of-coins contest! That is, we will calculate whose entry is best. The word “best” should remind you of optimization and indeed the winner of the contest will be the argmax of the relevant likelihood function. At this point, remember that the likelihood functions are \\({\\cal L}_m(\\text{contestant})\\), so the argmax will be one of the contestants!\nFirst, we need to pick the relevant likelihood function. Common sense tells us that you can only pick a winner when the jar has been opened and the money counted. That is, we need some data.\nHere’s the data: The officials have opened the jar and carefully counted the money. There was $32.14 in the jar. This tells us that the relevant likelihood function is \\({\\cal L}_{\\$32.14}(\\text{contestant})\\).\nThe output of \\({\\cal L}_{\\$32.14}(\\text{contestant})\\) is the probability density assigned by the contestant to the observed value $32.14. You can read this from ?fig-jar-functions2). For your convenience, the observation \\(32.14\\) has been annotated with a faint brown vertical line.\nHere’s a tabular version of \\({\\cal L}_{\\$32.14}(\\text{contestant})\\).\n\n\n\n\\(\\text{contestant}\\)\n\\({\\cal L}_{\\$32.14}(\\text{contestant})\\)\n\n\n\n\nJohnny\n0.000 per dollar\n\n\nLouisa\n0.010 per dollar\n\n\nGeoff\n0.066 per dollar\n\n\n\nIn statistics, likelihood functions are used to describe how to estimate a quantity given some data about the quantity. The techique is called maximum likelihood estimation: the estimate is the argmax of the likelihood function. For the coins-in-jar contest, the argmax is Geoff. Therefore, Geoff wins!\nIn the spirit of “Monday morning quarterbacking,” let’s look carefully at Johnny’s entry. If his bar-shaped probability density function were shifted just a little to the right, he would have won. This illustrates a weakness in Johnny’s logic in constructing his probability density function. The function indicates that he thought the probability of the amount being $23 was the same as being 30 dollars. In other words, he was uncertain to a considerable extent. But given this uncertainty, why would he insist that $30.01 is impossible (that is, has probability density 0 per dollar). Wouldn’t it make more sense to admit nonzero density for $30.01, and similarly for $30.02 and upward, with the density gradually decreasing with the amount of money. This is why, absent very specific knowledge about the circumstances, probability densities are so often framed as Gaussian distributions, as in Geoff’s entry.\n\nThe previous example is intended to give you an idea about what a likelihood function is. In that example, we use the calculus operator argmax to find the contest winner.\nLet’s turn now to another important use of likelihood functions: their role in the Bayesian inference process. The example concerns figuring out the risk of disease transmission.\n\nConsider the situation in November 2019 at the start of the COVID-19 pandemic. At that time, there was almost no information about the illness or how it spreads. In the US and many other countries, most people assumed that the spread of illness outside its origin in Wuhan, China, would be prevented by standard public health measures such as testing, contact tracing, quarantine, and restrictions on international travel. Intuitively, most people translated this assumption into a sense that the personal risk of illness was small.\nIn communicating with the public about risk, it is common to present risk as a number: a probability. This is an adequate presentation only when we have a solid idea of the risk. To form a solid idea, we need evidence.\nBefore there is enough evidence responsibly to form a solid idea, it is best to present risk not as a probability but as a probability density function. To illustrate, Figure 50.7) shows three different examples of what such probability density functions might look like for vague, preliminary ideas of risk.\n\n\n\n\n\nFigure 50.7: Three different opinions about the risk of a disease.\n\n\n\n\nPanel (A) in Figure 50.7 is a strong statement that the risk is believed to be small. Even so, the density function is non-zero even for values of the risk near 100%. This is an honest admission that, as with COVID-19, something that we don’t know might be going on. In the case of COVID-19, what most people didn’t realize is 1) that the reported numbers were completely unrepresentative of the extent of spread, since most cases are asymptomatic and 2) that the illness can spread even by those who are asymptomatic. Epidemiologists and other public health workers knew enough from previous experience to be aware of their lack of knowledge about (1) and (2), but the rest of us, including many policy makers, didn’t even know what they didn’t know. The word “unk-unk” is sometimes used by engineers to refer to such an “unknown unknown”.\nPanel (B) says, “I have no idea!” This can often be an honest, useful appraisal of the situation. But experts who are honest in this way are often regarded by the public and policy makers as lacking credibility.\nPanel (C) expresses the belief that the risk might well be small but also might be large.\nAny of the three probability density functions would be reasonable statements about what we knew and didn’t know about COVID-19 at the very beginning of the pandemic, before there was much data. Such statements are called priors; summaries of what we know up to the present.\nIn Bayesian inference, as data become available we can revise or update the priors, giving a better informed description of the risk.\nFor COVID-19, data eventually came in many different forms: estimates of incubation periods, testing to determine what fraction of cases are asymptomatic, and so on.\nFor our presentation of Bayesian reasoning, we will consider a simplified situation where data come in only one form: screening tests for the illness. Imagine that you are conducting a contact-tracing study. Whenever a patient presents with COVID-19 symptoms and has a positive PCR test, that patient’s close contacts are given a screening test for COVID. The objective is to estimate how transmissible the virus is by figuring out what proportion of close contacts become infected.\nWe cannot know which of the three priors in Figure 50.7 is most appropriate. After all, until rich enough data become available, each prior is just an opinion. So we will repeat the update-with-data analysis for each of the three priors. If, in the end, the results from the three priors substantially agree, then we can conclude that the data is shaping the results, rather than the prior.\nThe unknown here is the risk \\(R\\) of transmission. We will denote the three priors as \\(\\text{prior}_A (R)\\), \\(\\text{prior}_B (R)\\), and \\(\\text{prior}_C (R)\\). But, in general, we will write \\(\\text{prior}(R)\\) to stand for any of those three specific priors.\n\nIn Bayesian inference, the prior represents the starting point for what we know (or, more precisely, “believe”) about the risk of transmission. It has the form of a relative density function. As data come in, we update our prior beliefs on the basis of the data.\nAfter we have updated our prior, our state of knowledge is called a posterior belief. Think of the prior as “pre-data” belief and the posterior as “post-data” belief. The posterior also has the form of a relative density function.\nThe formula for updating is called Bayes’ Rule: posterior is likelihood times prior.\n\\[\\text{posterior}(R) = {\\cal L}_\\text{data}(R) \\times \\text{prior}(R)\\ .\\]\nRecall that the output of a likelihood function is a non-negative quantity. Since the prior is a relative density function, it too is non-negative for all \\(R\\). Therefore the posterior will have a non-negative output and be a valid relative density function.\n\nMost texts prefer to define priors and posteriors as probability density functions rather than relative density functions. The only difference, of course, is the normalization. But that can be performed at any time, so to streamline the updating process, we will let posteriors and priors be relative density functions.\n\nNotice that the posterior has just one input, the parameter \\(R\\). That is because the \\(\\text{data}\\) is fixed by our observations: the posterior only makes sense once we have the data available to choose the relevant likelihood function.\nOur task now is to construct the appropriate likelihood function that reflects how the screening test works. To outline the process, let’s consider a group of 1000 people who are taking the screening test. If we knew the parameter \\(R\\), we could split those 1000 people into two groups: one group with the illness and one group without.\n\nWhole group of 1000, made up of\n\n1000 \\(R\\) with the illness\n1000 \\((1-R)\\) without the illness\n\n\nFor instance, if \\(R=0.2\\), then out of the whole group of 1000 people, 200 would have the illness and 800 would not.\nAfter taking the screening test, each person will have either a positive test result (we will write this “+”) or a negative test result (we will write “-”).\nto make sense of a screening test, you need to know two probabilities. These are:\n\nThe probability of a + test in a group of people with the disease. We will call this \\(p_d(+)\\).\nThe probability of a - test in a group of people without the disease. we will call this \\(p_h(-)\\).\n\nNote that the subscript indicates whether we are referring to the probability in the has-the-illness group (\\(p_d\\)) or in the no-illness (“healthy”) group (\\(p_h\\)).\nYou may know that the result of a screening test is not definitive. That is, a person with a \\(+\\) result may not have the illness. Likewise, a \\(-\\) result is no guarantee that the person does not have the illness. The word “screening” is meant to emphasize the imperfections of such tests. But often the imperfect test is the best we have available.\nAfter the screening test has been taken by the 1000 people in our example group, we can divide them further\n\nWhole group of 1000, made up of\n\n1000 \\(R\\) with the illness, made up of\n\n1000 \\(R\\ p_d(+)\\) who had a correct positive test result\n1000 \\(R\\ (1-p_d(+))\\) who had a negative result despite having the illness\n\n1000 \\((1-R)\\) without the illness, made up of\n\n1000 \\((1-R)\\ (1-p_h(-))\\) who had a positive test result despite being healthy\n1000 \\((1-R)\\ p_h(-)\\) who had a correct negative result.\n\n\n\n\nSuppose that \\(R=0.2\\), \\(p_d(+) = 80\\%\\), and \\(p_h(-) = 70\\%\\). Then the division would be:\n\nWhole group of 1000, made up of\n\n200 with the illness, of whom\n\n160 who got a correct \\(+\\) result\n40 who got a \\(-\\) result, despite having the illness\n\n800 without the illness, of whom\n\n240 who got a \\(+\\) result, despite not having the illness\n560 who got a correct \\(-\\) result.\n\n\n\nThere are two likelihood functions reflecting the two different possible test results: \\({\\cal L}_+ (R)\\) and \\({\\cal L}_- (R)\\). We will need to construct both of these functions since the test result is going to be \\(+\\) for some people and \\(-\\) for others.\nRecall now that each likelihood function is based on a hypothesis about the world. In this case, the hypothesis is a particular value for \\(R\\). Let’s look at the situation for the hypothesis that \\(R=0.2\\). We can figure out the values of both \\({\\cal L}_+ (R=0.2)\\) and \\({\\cal L}_- (R=0.2)\\) from the breakdown given in the above example.\n\\({\\cal L}_+ (R=0.2)\\) is the probability of observing the given data (\\(+\\)) in the hypothetical world where \\(R=0.2\\). Out of the 1000 people, 160 will get a correct test result \\(+\\) and 240 people will get a \\(+\\) despite not having the illness. Therefore, \\[{\\cal L}_+ (R=0.2) = \\frac{160+240}{1000} = 40\\%\\ .\\]\nSimilarly, \\({\\cal L}_- (R=0.2)\\) is the probability of observing the given data (\\(-\\)) in the hypothetical world where \\(R=0.2\\). In the above breakdown, altogether 600 people received a \\(-\\) result: 560 of these were indeed healthy and 40 had the illness but nonetheless got a \\(-\\) result. So,\n\\[{\\cal L}_- (R=0.2) = \\frac{40+560}{1000} = 60\\%\\ .\\]\n\nThe above example calculated the output of the likelihood function for both \\(+\\) and \\(-\\) results when \\(R=0.2\\). We can repeat the calculation for any other value of \\(R\\). The results, as you can confirm yourself, are\n\\[{\\cal L}_+(R) = p_d(+)\\ R + (1-p_h(-))\\ (1-R) \\]\nand\n\\[{\\cal L}_-(R) = (1-p_d(+))\\ R + p_h(-)\\, (1-R)\\ .\\]\nIn a real-world situation, we would have to do some experiments to measure \\(p_h(-)\\) and \\(p_d(+)\\). For our example we will set \\(p_d(+) = 0.8\\) and \\(p_h(-) = 0.7\\).\nNow that we have constructed the likelihood functions for the two possible observations \\(+\\) and \\(-\\), we can use them to update the priors.\nSuppose our first observations are the results of screening tests on ten randomly selected individuals.\n\n\n\nSubject ID\nTest outcome\n\n\n\n\n4349A\n\\(+\\)\n\n\n7386A\n\\(-\\)\n\n\n6263E\n\\(+\\)\n\n\n5912C\n\\(-\\)\n\n\n7361C\n\\(-\\)\n\n\n9384C\n\\(-\\)\n\n\n6312A\n\\(-\\)\n\n\n3017C\n\\(+\\)\n\n\n1347B\n\\(-\\)\n\n\n9611D\n\\(-\\)\n\n\n\nTo summarize: Three \\(+\\) tests out of ten.\nAfter the first test outcome is available we can calculate the posterior: \\[\\text{posterior}_1 (R) = {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] After the second test outcome, the new posterior is \\[\\text{posterior}_2 (R) = {\\cal L}_-(R) \\times {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] And after the third (a \\(+\\) result!) it will be \\[\\text{posterior}_3 (R) = {\\cal L}_+(R) \\times {\\cal L}_-(R) \\times {\\cal L}_+(R) \\times \\text{prior(R)}\\ .\\] We continue on in this way through all ten rows of the data to get the posterior distribution after all 10 test results have been incorporated.\nFigure 50.9 shows the posterior after the 10 rows of data have been considered for each of the three priors from Figure 50.7).\n\n\n\n\n\n\n\n\nFigure 50.8: Posteriors (blue) after the first screening test, which was \\(+\\), for each of the priors in Figure 50.7. The prior itself is drawn in gray.\n\n\n\n\nWith just one row of data considered, the posteriors depend very much on the particular prior selected. This shouldn’t be a surprise; one test result from an imperfect screening test is not going to tell us much. Let’s process all of the\n\n\n\n\n\nFigure 50.9: Posteriors (blue) after the first ten rows of data, for each of the priors in Figure 50.7. The prior itself is drawn in gray.\n\n\n\n\nAfter the first 10 rows of data have been considered, the posteriors are similar despite the different priors.\n\n\n\n\n\nFigure 50.10: Posteriors (blue) after 100 subjects have been screen, with 30 \\(+\\) results.\n\n\n\n\nAs data accumulates, the priors become irrelevant; the knowledge about the risk of disease is being driven almost entirely by the data.\nRemarkably, even though 30% of the tests were positive, all the posteriors place almost all the probability density on transmission risks less than 20%. This is because the likelihood functions correctly take into account the imperfections of the screening test."
  },
  {
    "objectID": "Manifestations/B4-probability.html#exercises",
    "href": "Manifestations/B4-probability.html#exercises",
    "title": "50  Probability and evidence",
    "section": "50.5 Exercises",
    "text": "50.5 Exercises\n\nExercise 51.01\nIn Figure 50.4 estimate the area under each of the three curves. Which of these is true? Keep in mind that your estimates will at best be an approximation, so remember to use your theoretical knowledge of probability density functions to refine your estimates.\n\narea(Johnny) > area(Louisa)\narea(Louisa) > area(Geoff)\narea(Geoff) > area(Johnny)\nnone of the above\n\n\n\nExercise 51.03\nExponential distributions are self similar. Looking at ?fig-exponential-density and assume that \\(1/k = 100\\) days. According to the density function, the probability of an event happening in the first 100 days is 63.2%. Of course that means there is 36.8% chance that the event will happen after the 100 day mark. If the event does not happen in the first 100 days, there is a 63.2% chance that it will happen in interval 100-200 days. Similarly, if the event does not happen in the first 200 days, there is a 63.2% chance that it will happen in interval 200-300 days. Use these facts to calculate the probability mass in each of these intervals:\n\n0-100 days\n100-200 days\n200-300 days\n300-400 days\n\nHint: Make sure that the sum of these probability masses does not exceed 1.\n\n\nExercise 51.04\nThe functions dunif(), dnorm(), and dexp(), respectively, implement the uniform, gaussian, and exponential families of distributions. The word “family” is used because each each family has it is own parameters:\n\nUniform: min and max\nGaussian: mean and sd\nExponential: rate (with the exponential function parameterized as \\(\\exp\\left(-\\frac{t}{\\text{rate}}\\right)\\).)\n\nPick 3 very different sets of parameters for each family. (They should be meaningful, for instance sd \\(>0\\) and rate \\(>0\\).)\n\nNumerically integrate each of the 9 distributions to confirm that the total probability is 1.\nCompute the expectation value of each of the 9 distributions.\nCompute the variance of each of the 9 distributions.\n\nHand in your commands for each of the above tasks and the corresponding output.\n\n\nExercise 51.05\nPlot out dnorm() on semi-log axis. You can choose your own mean and sd, and your graphics domain should cover at least mean \\(\\pm 3\\)sd.\n\nDescribe the shape of the function graph on semi-log axes.\nExplain what about the graphic indicates that dnorm(x) will never be zero for any finite x.\n\n\n\nExercise 51.07\n\\(e^{-k x}\\) can be thought of as a relative density function. Why?\n\nThe exponential probability function dexp() is a scaled version of the relative density function. Find, symbolically, the scalar by which \\(e^{-k x}\\) must be multiplied to turn it into a probability density function.\n\n\n\nExercise 51.08\nCount the grid squares under the probability density function in ?fig-exponential-density and calculate the area a single grid square. What’s the total area under the curve? Make sure to give units, if any.\n\n\nExercise 51.10\nCalculate symbolically the expectation value and variance of the uniform distribution with parameters \\(a\\) and \\(b\\):\n\\[\\text{unif}(x, a, b) \\equiv \\left\\{{\\Large\\strut}\\begin{array}{cl}\\frac{1}{b-a}& \\text{for}\\ a \\leq x \\leq b\\\\0& \\text{otherwise} \\end{array}\\right.\\]\n\n\nExercise 51.12\nIn the Social Security life-table M2014F, one column is nliving. The nliving variable is computed by tracking the age-specific mortality rate as it plays out in a hypothetical population of 100,000 newborns. The age-specific mortality rate at age 0 is applied the the 100,000 to calculate the number of deaths in the first year: 531. Therefore 99,469 survive to age 1. Then the age-specific mortality rate at age 1 is applied to the 99,469 survivors to calculate the number of deaths of one-year olds: 34. This leaves 99,434 surviving two-year olds. (There is round-off error, involved, which is why the number is not 99,435.) The process is continued up through age 120, at which point there are no survivors.\nThe following R code constructs from M2014F a function died_before(age) giving the fraction of the cohort of 100,000 who died at or before the given age.\n\ndied_before <- M2014F %>%\n  select(age, nliving) %>%\n  mutate(prob = nliving/100000) %>%\n  spliner(1-prob ~ age, data = .)\n\n\nPlot out died_before(age) vs age. Explain what you see in the graph that tells you that this is a cumulative probability function.\nTo calculate life-expectancy, we need to convert died_before(age) into died_at(age), the probability density of death at any given age. Use R/mosaic to construct died_at(age), which will be a basic calculus transformation of died_before().\n\n\n\n\n\nWhat are the units of the output of the died_at(age) function?\n\n\n\nFind the expectation value of age under the probability density died_at(age). This is called the life-expectancy at birth: the average number of years of life of the people in the imaginary cohort of 100,000.\n\n\n\n\n\n\nExercise 51.13\nThe R code below will construct a function, prob_death60(age) that gives the probability that a person reaching her 60th birthday will die at any given age. (The function is constructed from US Social Security administration data for females in 2014.)\n\nprob_death60 <- M2014F %>%\n  filter(age >= 60) %>%\n  select(age, died) %>%\n  mutate(prob = died/91420) %>%\n  spliner(prob ~ age, data = .)\n\n\nThe “life expectancy at age 60” is the expectation value for the number of years of additional life for person who reaches age 60. (The number of years of additional life is age - 60.) Compute the life-expectancy at age 60 based on the prob_death(age) function.\n\n\n\n\n\nA more technically descriptive name for life-expectancy would be “expectation value of additional life-duration.” Calculate the standard deviation of “additional life-duration.”\n\n\n\n\n\nConstruct the cumulative probability function for age at death for those reaching age 60. (Hint: Since the value of the cumulative at age 60 should be 0, set the argument lower.bound=60 in antiD() so that the value will be zero at age 60.) From the cumulative, find the median age of death for those reaching age 60. (Hint: Zeros().)\n\n\n\n\n\nIn a previous exercise, we found from these same data that the life expectancy at birth is about 81 years. Many people mis-understand “life expectancy at birth” to mean that people will die mainly around 81 years of age. That is not quite so. People who are approaching 81 should keep in mind that they likely have additional years of life. A good way to quantify this is with the life-expectancy at age 81. We can calculate life-expectancy at 81 based on the prob_death60(). You can do this by scaling prob_death60() by \\(A\\) such that \\[\\frac{1}{A}  = \\int_{81}^{120} \\text{prob\\_death60}(\\text{age})\\, d\\text{age}\\ .\\]\n\n\nCalculate \\(A\\) for age 81.\n\n\n\n\n\nUsing the \\(A\\) you just calculated, find the life-expectancy at age 81, that is, the expectation value of additional years of life at age 81. Also calculate the standard deviation.\n\n\n\n\n\n\nExercise 51.15\nUNDER CONSTRUCTION\nOne of the goals for self-driving cars is to reduce road accidents, especially fatal accidents. People are understandably skeptical that an automated system can cope with all the varying conditions of traffic, visibility, road damage, etc. without the benefit of human judgment or experience. For this reason, society will need to accumulate substantial evidence for enhanced safety in self-driving cars before accepting any claims to that effect.\nThis exercise is about how to accumulate such evidence.\nBased on experience with tens of millions of regular cars driving hundreds of billions of total miles, suppose we decide the accident probability is approximately 10% per 20,000 miles. Note that this is not stating that an accident is certain to occur in the first 200,000 miles of driving. The probability that, for a representative car, an accident occurs at \\(m\\) miles will have an exponential shape \\(g(m, k)\\) where \\[g(m, D) \\equiv \\frac{1}{D} e^{-m/D}\\, .\\] Consequently, an accident might happen in the first few miles or at 300,000 miles or not at all within the lifetime of the car.\nTake note that we have parameterized the exponential with \\(D\\), which will have units of miles. Thus, bigger \\(D\\) means a safer car. You can think about \\(D\\) as indicating the distance traveled by a typical car before it has an accident.\nPart A. Estimate the \\(D\\) to be consistent with the idea that there is a 10% chance of an accident at or before the first \\(m=20,000\\) miles of driving.\n\nRecognize that “at or before” corresponds to a cumulative probability function which in this case will be \\[\\int_0^m \\frac{1}{D} e^{- x/D}\\, dx\\ .\\]\nConstruct the cumulative probability density in symbolic form. It will be a function of both \\(D\\) and \\(m\\), let’s call it \\(G(m, D)\\).  (Hint: \\(G(0, D)\\) must be zero. \\(G(m, D)\\) will have a roughly sigmoid increase with \\(m\\). \\(\\lim_{m \\rightarrow \\infty} G(m, D) = 1\\).)\nSet \\(G(m=20000, D_0) = 0.10\\), per our assumption for ordinary cars of a 10% risk in \\(m=20,000\\) miles of driving. Solve this to find \\(D_0\\). \n\nShow your work.\nTo start the calculations, we will need a prior relative density function for \\(k\\). We are hopeful but skeptical about self-driving cars. The best case scenario, let’s say, is that the self-driving cars will be 10 times safer than regular cars. The worst case is that they will be 10 times worse. Using \\(k\\) as our measure of safety, we will set our prior to have the form \\(1/D\\).\nPart B: Implement the function \\(\\text{prior}(D) = 1/D\\).\n\n\n\n\nGraph out \\(\\text{prior}(D)\\) on the domain 2,000 to 2,000,000, that is, roughly \\(D_0/10\\) to \\(10 D_0\\).\nReferring to your graph, write down your intuition about whether this prior seems to favor \\(D < D_0\\) or not.\nNow remember that \\(\\text{prior}(D)\\) shows relative density. So compare the total probability that \\(D_0/10 \\leq D \\leq D_0\\) to the probability of \\(D_0 \\leq D \\leq 10 D_0\\) \\[\\int_{20,000}^{200,000} \\text{prior}(D)\\, dD\\ \\ \\ \\ \\ \\text{to}\\ \\ \\ \\ \\ \\int_{200,000}^{2,000,000} \\text{prior}(D)\\, dD\\ .\\] Does this indicate that the \\(1/D\\) prior is biased toward the assumption that self-driving cars will be no safer than ordinary cars? Explain your reasoning.\n\nNow imagine that you work for a safety organization collecting accident information. To figure out the safety of self-driving cars, you are monitoring a fleet of 100 self-driving cars. Each year you get a report giving the odometer reading of the car, or, if the car has been in an accident that year, the odometer reading at the time of the accident. The data might look like the following table. (The table is entirely fictitious and shouldn’t be misinterpreted as representing real-world self-driving cars.):\n\n\n\n\\(i\\)\nStatus\nMileage\n\n\n\n\n1\non road\n85,300\n\n\n2\non road\n65,200\n\n\n3\naccident\n13,495\n\n\n4\non road\n131,200\n\n\n5\non road\n96,000\n\n\n6\naccident\n54,682\n\n\n7\naccident\n105,200\n\n\n8\non road\n53,900\n\n\n9\naccident\n86,000\n\n\n10\non road\n94,300\n\n\n\\(\\vdots\\)\n\\(\\vdots\\)\n\\(\\vdots\\)\n\n\n100\non road\n107,200\n\n\n\n\n\n\nThe first two cars in the fleet have accumulated 85,300 and 65,200 accident-free miles respectively. The third car was in an accident at 13,495 miles and is no longer on the road.\nIn response to the data, you issue a yearly report in the form of a posterior distribution on \\(D\\), our measure of safety.\nTo update the original prior into a posterior, you need to construct the likelihood functions. There are two functions, because there are two different kinds of observations on each car:\n\nIf the car was in an accident, then you want the likelihood of \\(D\\) given the mileage at which the accident happened. Since the probability model is \\(\\frac{1}{D}\\, e^{-D\\, m}\\), the likelihood function for a car that had an accident at \\(m_\\text{accident}\\) miles will be \\(\\frac{1}{D}\\, e^{-D\\, m_\\text{accident}}\\).\nIf the car has not been in an accident, then you want the likelihood of \\(D\\) given the number of miles traveled.\n\nThe likelihood function (b) is based on the probability model that the car has not had an accident in \\(m_\\text{driven}\\) miles of driving. Recall that the cumulative probability, \\(G(m, D)\\) in part A of this exercise, is the probability that the car did have an accident at or before \\(m\\) miles of driving. So the probability that the car did not have an accident in that amount of driving is \\(1 - G(m, D)\\). The likelihood function will therefore be \\(1 - G(m_\\text{driven}, D)\\).\nPart C. Implement the two likelihood functions in R as Laccident(m, D) and Lno(m D).\n\n\n\nPlot out the two functions and explain why their shape makes sense. Show the code that implements the two functions.\nNow you are in a position to update the prior to create the posterior probability density on \\(D\\) given the data at hand. As always with Bayesian inference, the posterior will be: \\[\\text{posterior}(D) = \\frac{1}{A} \\prod_\\text{cars}\\text{likelihood}_i(D | \\text{miles}_i) \\text{prior}(D)\\] where \\(\\text{likelihood}_i()\\) refers to whichever one of the two likelihood functions in Part C is relevant to car \\(i\\) and \\(\\text{miles}_i\\) is the observed mileage for that car. The constant \\(A\\) is selected to normalize the posterior probability density.\nPart D. To keep things simple, we will use just the first 10 cars in the fleet report. The unnormalized posterior function will be:\n\npost <- function(D) {\n  Lno(85300, D) * Lno(65200, D) * \n  Laccident(13495, D) * Lno(131200, D) *  \n  #similarly for each of the remaining cars ...\n  prior(D)\n}    \n\nBased on the data from the first 10 cars, do you think that the self-driving cars are safer than the ordinary cars? Recall that \\(D_0\\), calculated above, represents the safety of ordinary cars."
  },
  {
    "objectID": "Manifestations/B4-future-value.html",
    "href": "Manifestations/B4-future-value.html",
    "title": "51  Present and future value",
    "section": "",
    "text": "Comparison is an important element of human decision making. Often, comparison amounts to translating each of the options at hand into a scalar score. (Recall that a scalar is just an ordinary quantity, e.g. 73 inches. As we get more deeply involved with vectors it will become more important to be perfectly clear when we are talking about a vector and when about a scalar. So we will be using “scalar” a lot.) Scalars are easy to compare; the skill is taught in elementary school. Scalar comparison is completely objective. Putting aside the possibility of error, everyone will agree on which of two numbers is bigger. Importantly, comparison of scalars is transitive, that is if \\(a > b\\) and \\(b > c\\) then it is impossible that \\(a \\leq c\\).\nThe comparison of scalars can be extended to situations where the options available form a continuum and the score for each option \\(x\\) is represented by a function, \\(f(x)\\). As we saw in Chapter 24 and Chapter 49, selecting the highest scoring option is a matter of finding the argmax.\nMany decisions involve options that have two or more attributes that are not directly comparable. Expenditure decisions have this flavor: Is it worth the money to buy a more reliable or prettier or more capable version of a product? The techniques of constrained optimization (Chapter 49) provide one useful approach for informing decisions when there are multiple objectives.\nElections are a form of collective decision making. The options—called, of course, “candidates”—have many attributes. Three such attitudes are attitudes toward social policy, toward fiscal policy, and toward foreign policy. Perceived honesty and trustworthiness as well as the ability to influence other decision makers and perceived ability to win the election are other attributes that are considered and balanced against one another. Ultimately the decision is made by condensing the diverse attributes into a single choice for each voter. The election is decided by how many votes the candidate garners. With this number attached to each of the candidates, it is easy to make the decision,\n\\[\\text{winner} \\equiv\\mathop{\\text{argmax}}_{i} \\text{votes}(\\text{candidate}_i)\\ .\\]\nThere are many voting systems. For instance, sometimes the winner is required to have a majority of votes and, if this is not accomplished, the two highest vote-getting candidates have a run-off. Some jurisdictions have introduced “rank-choice” voting, where each voter can specify a first choice, a second choice, and so on. US federal elections involve a primary system where candidates compete in sub-groups before the groups complete against one another. It is tempting to think that there is a best voting system if only we were clever enough to find one and convince authorities to adopt it. But two mathematical theorems, Arrow’s impossibility theorem and the Gibbard-Satterthwaite theorem demonstrate that this is not the case for any system that involves three or more candidates. All such voting systems potentially create situations where a voter’s sincere interests are best served by an insincere, tactical vote choice. A corollary is that voters can be tricked into making a sincere choice that violates their interests.\nThis chapter is about a very common situation where there are multiple attributes that need to be condensed into a single score. The setting is simple: money. The question is how to condense a future income/expense stream—a function of time—into an equivalent value of money in hand at the present. This is called the present value problem. There is a solution to the problem that is widely accepted as valid, just as voting is a hallowed process of social optimization. But like voting, with its multiplicity of possible forms, there is a subtlety that renders the result somewhat arbitrary. This is not a situation where there is a single, mathematically correct answer but rather a mathematical framework for coming to sensible conclusions."
  },
  {
    "objectID": "Manifestations/B4-future-value.html#present-value",
    "href": "Manifestations/B4-future-value.html#present-value",
    "title": "51  Present and future value",
    "section": "51.1 Present value",
    "text": "51.1 Present value\nPeople and institutions often have to make decisions about undertakings where the costs and benefits are spread out over time. For instance, a person acquiring an automobile or home is confronted with a large initial outlay. The outlay can be financed by agreeing to pay amounts in the future, often over a span of many years.\nAnother example: Students today are acutely aware of climate change and the importance of taking preventive or mitigating actions such as discouraging fossil fuel production, investing in renewable sources of energy and the infrastructure for using them effectively, and exploring active measures such as carbon sequestration. The costs and benefits of such actions are spread out over decades, with the costs coming sooner than the benefits. Policy makers are often and perhaps correctly criticized for overvaluing present-day costs and undervaluing benefits that accrue mainly to successive generations. There are many analogous situations on a smaller scale, such as setting Social Security taxes and benefits or the problem of underfunded pension systems and the liability for pension payments deferred to future taxpayers.\nThe conventional mechanism for condensing an extended time stream of benefits and costs is called discounting. Discounting is based on the logic of financing expenditures via borrowing at interest. For example, credit cards are a familiar mechanism for financing purchases by delaying the payment of money until the future. An expense that is too large to bear is “carried” on a credit card so that it can be paid off as funds become available in the future. This incurs costs due to interest on the credit-card balance. Typical credit-card interest rates are 18-30% per year.\nAs notation, consider a time stream of income \\({\\cal M}(t)\\), as with the apartment building example. We will call \\({\\cal M}(t)\\) the nominal income stream with the idea that the money in \\({\\cal M}(t)\\) is to be counted at face value. “Face value” is the literal amount of the money. In the case of cash, a $20 bill has a face value of $20 regardless of whether it becomes available today or in 50 years. The word “nominal” refers to the “name” on the bill, for instance $20.\nThe big conceptual leap is to understand that the present value of income in a future time is less than the same amount of income at the present time. In other words, we discount future money compared to present money. For example, if we decide that an amount of money that becomes available 10 years into the future is worth only half as much as that same amount of money if it were available today, we would be implying a discounting to 50%. In comparison, if that money were available 20 years in the future, it would make sense to discount it by more strongly to, say, 25%.\nTo represent the discounting to present value as it might vary with the future time horizon, we multiply the nominal income stream \\({\\cal M}(t)\\) by a discounting function \\({\\cal D} (t)\\). The function \\({\\cal D}(t)\\, {\\cal M}(t)\\) gives the income stream as a present value rather than a nominal value. It is sensible to insist that \\({\\cal D} (t=0) \\equiv 1\\) which is merely to say that the present value of money available today is the same as the nominal value.\nThe net present value (NPV) of a nominal income stream \\({\\cal M}(t)\\) is simply the sum of the stream discounted to the present value. Since we are imagining that the income stream is a function of continuous time, the sum amounts to an integral: \\[\\text{NPV} \\int_\\text{now}^\\text{forever} {\\cal M}(t)\\ {\\cal D}(t)\\, dt\\ .\\]"
  },
  {
    "objectID": "Manifestations/B4-future-value.html#sec-discount-functions",
    "href": "Manifestations/B4-future-value.html#sec-discount-functions",
    "title": "51  Present and future value",
    "section": "51.2 Discounting functions",
    "text": "51.2 Discounting functions\nWhat should be the shape of the discounting function?\nRecall that the purpose of the discounting function is to help us make comparisons between different income streams, that is, between the various options available to an entrepreneur. Each individual can in principle have his or her own, personal discounting function, much as each voter is entirely free to weight the different attributes of the candidates when deciding whom to vote for. As a silly example, a person might decide that money that comes in on a Tuesday is lucky and therefore worth more than Thursday money. We won’t consider such personalized forms further and instead emphasize discounting functions that reflect more standard principles of finance and economics.\nAs a thought experiment, consider the net present value of an income stream, that is\n\\[\\text{NPV}_\\text{original} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(t)\\, dt\\ .\\]\nImagine now that it has been proposed to delay the income stream by \\(T=10\\) years. This new, delayed income stream is \\({\\cal M}(t-T)\\) and also has a net present value:\n\\[\\text{NPV}_\\text{delayed} = \\int_0^\\infty {\\cal M}(t - T)\\ {\\cal D}(t)\\, dt\\ .\\]\nThere are at least two other ways to compute \\(\\text{NPV}_\\text{delayed}\\) that many people would find intuitively reasonable:\n\nSimply discount the original NPV to account for it becoming available \\(T\\) years in the future, that is, \\[\\text{NPV}_\\text{delayed} = {\\cal D}(T)\\ \\text{NPV}_\\text{original} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(T)\\ {\\cal D}(t)\\, dt\\ \\]\nApply to \\({\\cal M}(t)\\) a discount that takes into account the \\(T\\)-year delay. That is:\n\n\\[\\text{NPV}_\\text{delayed} = \\int_0^\\infty {\\cal M}(t)\\ {\\cal D}(t + T)\\, dt\\ .\\]\nFor (1) and (2) to be the same, we need to restrict the form of \\({\\cal D}_r(t)\\) so that\n\\[{\\cal D}(T)\\ {\\cal D}(t) = {\\cal D} (t+T)\\ .\\]\nThe form of function that satisfies this restriction is the exponential, that is \\({\\cal D}(t) \\equiv e^{kt}\\)."
  },
  {
    "objectID": "Manifestations/B4-future-value.html#compound-interest",
    "href": "Manifestations/B4-future-value.html#compound-interest",
    "title": "51  Present and future value",
    "section": "51.3 Compound interest",
    "text": "51.3 Compound interest\nA more down-to-earth derivation of the form of \\({\\cal D}(t)\\) is to look at how financial transactions take place in the everyday world: borrowing at interest. Suppose that a bank proposes to lend you money at an interest rate of \\(r\\) per year. To receive from the bank one dollar now entails that you pay the bank \\(1+r\\) dollars at the end of the year.\nFor this proposition to be attractive to you, the present value of \\(1+r\\) dollars to be paid in one year must be less than or equal to the present value of one dollar today. In other words,\n\\[{\\cal D}_\\text{you}(1)\\ (1+r) \\leq 1\\ .\\]\nFrom the bank’s perspective, the present value of your payment of \\((1+r)\\) dollars in a year’s time must be greater than one dollar today. That is\n\\[1 \\leq {\\cal D}_\\text{bank}(1)\\ (1+r) \\ .\\]\nIt is perfectly reasonable for you and the bank to have different discounting functions, just as it is perfectly legitimate for you and another voter to have different opinions about the candidates. It is convenient, though to imagine that the two discounting functions are the same, which will be the case if \\[{\\cal D}(1) = \\frac{1}{1+r}\\ .\\]\nIf you were to borrow money for two years, the bank would presumably want to charge more for the loan. A typical practice is to charge compound interest. Compound interest corresponds to treating the loan as having two phases: first, borrow one dollar for a year and owe \\(1+r\\) dollars at the end of that year. At that point, you will borrow \\((1+r)\\) dollars at the interest rate \\(r\\). At the end of year two you will owe \\((1+r) (1+r) = (1+r)^2\\) dollars. In general, if you were to borrow one dollar for \\(t\\) years you would owe \\((1+r)^t\\) dollars. In order for the loan to be attractive to both you and the bank, the discounted value of \\((1+r)^t\\) should be one dollar:\n\\[{\\cal D}(t) = \\frac{1}{(1+r)^t} = (1 + r)^{-t}\\ .\\]\n\nLet’s return to the entrepreneur considering the apartment-building project.\nThe entrepreneur goes to the bank with her business plan and financial forecasts. The bank proposes to lend money for the project at an interest rate of 7% per year.\n\n\n\n\n\nFigure 51.2: Blue curve: The apartment project income stream discounted at 7% per year. Black curve: The undiscounted income stream.\n\n\n\n\nFigure 51.2 shows the income stream discounted at 7% per year. The net present value of the income stream for the apartment project is the accumulation of the discounted income stream:\n\\[\\text{NPV}(7\\%) = \\int_0^{30} (1 + 0.07)^{-t} {\\cal M}(t) \\ dt \\ .\\] This works out to be negative $1,095,000. As things stand, the apartment building will be a money pit.\nThe entrepreneur responds to the bank’s offer with some business jargon. “I’ll have to go back to the drawing board, put the team’s heads together, and see how to get the numbers to work. I’ll circle back with you tomorrow.” This might involve reconsidering her model of the income stream. Perhaps she should have taken into account yearly rent increases. Maybe she can re-negotiate with the city about zoning height restrictions and build a 12-unit building, which will cost $4 million, lowering the cost per apartment?"
  },
  {
    "objectID": "Manifestations/B4-future-value.html#mortgages",
    "href": "Manifestations/B4-future-value.html#mortgages",
    "title": "51  Present and future value",
    "section": "51.4 Mortgages",
    "text": "51.4 Mortgages\nA mortgage is a form of loan where you pay back the borrowed amount at a steady rate, month by month. At the end of a specified period, called the term of the mortgage, your have completely discharged the debt.\nSuppose you decide to buy a product that costs \\(\\$\\cal P\\), say \\(\\cal P=\\) $10,000 for a used car. Let’s say you need the car for your new job, but you don’t have the money. So you borrow it.\nYour plan is to pay an amount \\(A\\) each month for 30 months—the next \\(2\\,\\small\\frac{1}{2}\\) years. What should that rate be?\nYou can put the purchase on your credit card at an interest rate of \\(r=2\\%\\) per month. This corresponds to \\(k = \\ln(1+r) = 0.0198\\) per month. The net present value of your payments over 30 months at a rate of \\(A\\) per month will be\n\\[\\int_0^{30} A {\\cal D}_r(t)\\, dt = \\int_0^{30} e^{-kt} A = -\\frac{A}{k} e^{-kt}\\left.{\\Large\\strut}\\right|_{t=0}^{30}\\\\ =- A \\left(\\strut \\frac{e^{-30k}}{k} - \\frac{e^{-0k}}{k} \\right)\\\\ = - A\\left(\\strut27.88 - 50.50\\right) = 22.62 A\\]\nThe loan will be in balance if the net present value of the payments is the same as the amount \\({\\cal P}\\) you borrowed. For this 30-month loan, this amounts to \\[22.62 A = {\\cal P}\\ ,\\] from which you can calculate your monthly payment \\({\\cal A}\\). For the $10,000 car loan,\nyour monthly payment will be $10,000/22.62 or $442.09."
  },
  {
    "objectID": "Manifestations/B4-future-value.html#exercises",
    "href": "Manifestations/B4-future-value.html#exercises",
    "title": "51  Present and future value",
    "section": "51.5 Exercises",
    "text": "51.5 Exercises\n\nExercise 52.02\nVerify that the restriction \\[{\\cal D}(T)\\ {\\cal D}(t) = {\\cal D} (t+T)\\] is satisfied, for any \\(T\\) when \\[{\\cal D}(t) \\equiv e^{k t}\\ .\\] Also, confirm that, with this definition for \\({\\cal D}(t)\\), we have\n\\[{\\cal D}(t=0) = 1\\ .\\]\n\n\nExercise 52.04\nThe mathematician’s preferred format for discounting functions is \\(e^{kt}\\), while the banker’s is \\((1+r)^{-t}\\).\nDerive an expression for \\(k\\) in terms of \\(r\\) so that the mathematician’s and banker’s forms are completely equivalent.\nUse the computer to confirm your expression by plotting out both \\((1+r)^{-t}\\) and \\(e^{kt}\\), with \\(k\\) set according to your expression. (Hint: Pick a particular interest rate, say \\(r=7\\%\\).)\n\n\nExercise 52.06\nThe Powerball is a weekly lottery famous for its outsized payoff. For instance, for the week of April 7, 2021, the jackpot payout was officially described as $43,000,000. But they don’t really mean this.\nAfter withholding taxes, the supposed $43,000,000 amounts to $17,161,778 as a one time cash payment, or, alternatively, 30 annual payments of $873,711. (The tax numbers are for Colorado.) We want to find the discount rate that is implicit in the equating of $17M now with 30 payments of $875,000.\nDiscounted at a continuously compounded rate of \\(k\\), the net present value of a 30-year payment stream of $875K per year is \\[\\text{NPV}(k) = \\int_0^{30} e^{-kt}\\ \\$875000\\, dt\\ .\\]\n\nSolve this definite integral symbolically to find a formula for NPV\\((k)\\).\n\n\n\nUsing a sandbox, implement the function NPV\\((k)\\) in R.\n\n\n\n\n\nSolve for \\(k_0\\) that gives NPV\\((k_0) = \\$17,000,000\\).\n\n\n\n\n\nTranslate the continuously compounded interest rate \\(k\\) into the corresponding 1-year compounded interest rate \\(r\\).\n\n\n\n\nThere is a joke that makes sense only to the financially savvy: When the Powerball claims a $1 million payout, they mean $1 per year over a million years. We can do this calculation using the symbolic formula for NPV(t) but replacing the $875,000 with $1 and the 30 years upper limit of the integral with 1,000,000 years.\n\nSet the discount rate to the \\(k_0\\) you found in step (3) and calculate the net present value of $1 per year for a million years.\n\n\n\n\n\n\n\n\nExercise 52.08\nIn this exercise, you will calculate the net present value of the social security payments for a woman retiring at age 70. We will assume that benefits are paid at a rate of $24,000 per year.\nThe following R/mosaic commands will construct a function, survive(age) that gives the proportion of people alive at age 70 who will survive to an older age. (This is estimated from the Social Security mortality tables for 2014.)\n\nsurvive <- M2014F %>%\n  filter(age >= 70) %>%\n  select(age, nliving) %>%\n  mutate(survival = nliving / 82818) %>%\n  spliner(survival ~ age, data = .)\n\nFor a person living to age 100, the net present value at age 70 of the $24,000 annual social security benefit is\n\\[\\int_{70}^{100} 24000 \\exp(-k*(age-70))\\, dt\\]\nCalculate this amount for a continuously compounded interest rate of \\(k=0.03\\) per year\n\n\n\n\nBenefit payments stop when a beneficiary dies. Of course, it is not known ahead of time when a retiree will die, but the survive(age) function gives a probability of surviving to any given age.\n\nModify the integral to incorporate the survival probability into the net present value calculation. That is, calculate the expectation value of the net present value.\n\n\n\n\nIs survive(age) a probability density function? Explain why or why not."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html",
    "href": "Manifestations/B4-mechanics.html",
    "title": "52  Mechanics",
    "section": "",
    "text": "In Block 2, we introduced the ideas of instantaneous rate of change and infinitesimal intervals of time. These are mathematical concepts introduced in the 17th century for describing motion. (In the 16th century, Galileo’s measurements of motion involved averages over finite time intervals.) With this new mathematical tool, Newton understood that the velocity of an object is its instantaneous rate of change of position with respect to time, and to define acceleration as the instantaneous rate of change of velocity with respect to time. With these definition, Newton was able to connect motion to the palpable forces acting on objects. Thus was born the field of dynamics, the study of forces and their effects on motion.\nIn contrast, statics is about physical systems that do not change. A non-changing system is said to be in equilibrium or balance. Static systems are incredibly important in everyday life; a bridge that is not static is one that you do not want to cross! The equilibrium in a bridge is the balance between the downward force of gravity and the compressive and tensile forces in the materials that make up the bridge.\n“Mechanics” is a catch-all term for the combination of statics and dynamics studied in physics and used in engineering and design. The sense of the word is the study of machines, with the “-ic” signifying “practice of” in the sense of scientific, physics, mathematics, optics, chiropractic, and such. This starts with simple machines—simple devices that change the direction or strength of a force— such as the lever, wheel and axle, pulley, inclined plane, wedge, and screw. Mechanics goes on to deal with more complicated machine components such as a gas-filled cylinder and piston, flywheel, valve, turbine, etc. Many concepts originally developed for the theory of machines are familiar, and intuitive to the modern mind: force, pressure, momentum.\nThis chapter illustrates the central role of calculus concepts and methods in mechanics."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#work",
    "href": "Manifestations/B4-mechanics.html#work",
    "title": "52  Mechanics",
    "section": "52.1 Work",
    "text": "52.1 Work\n“Work” is a familiar, everyday concept, but a nuanced one; one person’s work can be another person’s play. In mechanics, work has a much more specific meaning stemming from the study of simple machines. A lever, for instance, can be used to move an object that is otherwise too heavy to handle. It still takes toil and effort to move the object, but the effort is eased by the mechanics of the lever.\nOur intuitive sense of work is perhaps rooted in physiology: effort, fatigue, muscle pain. For instance, it takes work to pick up a heavy object, but it is also work to hold the object steady even without moving it. Generations of thinking about machines has brought us to a different notion of work that does not involve human subjectivity. In mechanics, holding an object steady, no matter how heavy, does not involve work. Although a human tasked to hold a heavy load will become exhausted, the same duty can be accomplished by placing the load on a table, completely eliminating the effort. In mechanics, work and motion go hand in hand; without motion there is no mechanical work.\nThe table holding the heavy load does no work. Work is done only when the load is moved, and the amount of work depends on how the load is moved. For instance, moving a block along level ground involves a lot of work, but pulling a cart filled with blocks can be almost effortless. In mechanics, work combines both the amount of motion and the force needed to accomplish the motion.\n\nWork is force times displacement.\n\nConsider, for instance, the work involved in lifting a mass \\(m\\) to table height \\(h\\).\n\nknitr::include_graphics(\"www/mass-on-table.png\")\n\n\n\n\n\n\n\n\nThe lifting is accomplished by applying an upward force to counter the force of gravity. The gravitational force on the mass is \\(m g\\), where \\(g\\) is the instantaneous acceleration of an object released to fall freely (about 9.8 m/s2 near the Earth’s surface). The distance traveled is \\(h\\). So the work performed on the mass is \\(m g h\\).\nNotice that the mechanical work has nothing to do with the speed with which the mass is moved up to the table. Lift it fast or lift it slow, it amounts to the same mechanical work. (Of course, to human perception, lifting an object very slowly up to table height involves more effort than snapping it up quickly. But human effort is only peripherally related to mechanical work.)\nLet’s introduce a machine to the situation in the form of a ramp or a pulley. The purpose of the machine is to ease human labor by changing the strength or direction of forces. You can perhaps intuit that rolling the mass up the ramp will be an easier task than lifting it. How so?\n\nknitr::include_graphics(\"www/mass-up-ramp.png\")\n\n\n\n\n\n\n\n\nThe ramp can be seen as a sort of partial table. The ramp does most of what’s needed to hold the mass up. To keep the mass in place on the ramp the human worker need only supply a modest additional force parallel to the ramp surface. Calculating that modest additional force can be accomplished by a basic mathematical technique in mechanics: decomposing a vector.\nYou encountered vectors (in Section 24.003) in the context of the gradient vector of a function, say, \\(f(x,y)\\). At any given input \\((x,y)\\) the gradient vector, written \\(\\nabla f(x,y)\\), points in the steepest uphill direction of the function \\(f(x,y)\\). Recall that the gradient vector was written as a set of values; the partial derivative of \\(f()\\) with respect to each of its inputs in turn. That is, \\[\\nabla f(x,y) = \\left({\\large\\strut} \\partial_x f(x,y),\\ \\  \\partial_y f(x,y)\\right)\\ .\\] In this representation, the vector \\(\\nabla f(x, y)\\) is decomposed into two components: \\(\\partial_x f(x,y)\\) and \\(\\partial_y f(x,y)\\).\n\n\n\n\n\n\n\n\n\nTo decompose the vector of gravitational forces, we can place a coordinate grid over the gravity vector. In Figure 52.1 this grid has been arranged so that one cardinal direction is aligned with the ramp itself and the other is perpendicular—that is, “normal”—to the ramp. Merely by noting the coordinates of the gravitational vector in the coordinate grid, we decompose that vector into two components, one along the surface of the ramp and the other perpendicular to the ramp.\n\n\n\n\n\n\nFigure 52.1: Decomposing the vector of gravitational force into two perpendicular components, one tangent to the ramp and the other perpendicular to it. For clarity, the right triangle of decomposition is shown twice, once without the grid.\n\n\n\nWe return to the idea of vector decomposition in much more detail in Block 5 of this course; it has a major (though perhaps unexpected) role to play in fitting models to data. But for now, we will simply examine the right triangle in Figure 52.1. In that right triangle, the gravitational force vector \\(F_{gravity} = m g\\) is the hypotenuse. The component tangential to the ramp is \\(m \\sin(\\theta) g\\). The worker pushing the mass up the ramp need provide only tangential component of force which is smaller than the force imposed on the worker picking up the mass without a ramp. Thus human effort is reduced by the machine.\nWhat about the mechanical work? Is that also reduced? Remember that mechanical work is the product of force times distance. The force has been reduced to \\(m \\sin(\\theta) g\\), but the distance \\(D_{ramp}\\) along the ramp is much longer than the distance \\(h\\) from floor to table top.\n\n\n\n\n\n\n\n\n\nAgain, referring to the ramp itself as a right triangle, you can see that \\(D_{ramp}\\sin(\\theta) = h\\) or, \\(D_{ramp} = h / \\sin(\\theta)\\). The total mechanical work, the product of applied force times distance moved is \\[m \\sin(\\theta) g \\times D_{ramp} = m \\sin(\\theta) g \\times \\frac{h}{\\sin(\\theta)} = m g h\\ .\\] The ramp does nothing to reduce the mechanical work needed to lift the mass!\nWe usually think of ramps as an inclined plane. But, from Blocks 1 to 3 we have the tools to figure out the work for a (smooth) ramp with any shape at all. We will do this not because odd-shaped ramps are encountered frequently, but to provide an example in a relatively familiar setting of some techniques we will use elsewhere in this chapter.\nThe ramp we have in mind has a surface whose height \\(f(x)\\) is zero at the foot (\\(x=a\\)) and reaches \\(f(x=b) = h\\) where it joins the table.\n\n\n\n\n\n\n\n\n\nThe slope of the ramp at any location \\(x\\) is, as you know, \\(\\partial_x f(x)\\). It is helpful to convert this rise/run formulation of slope into the slope-angle form we used to study the simple ramp. As you can see from the diagram, which zooms in on one place on the ramp, rise over run amounts to \\(L\\sin(\\theta) / L\\cos(\\theta) = \\partial_x f(x) = \\tan(\\theta)\\), with the result:\n\\[\\theta = \\arctan({\\large\\strut}\\partial_x f(x))\\ .\\]\nConsequently, the force that needs to be applied parallel to the ramp’s surface is \\(m \\sin(\\arctan(\\partial_x f(x))) g = m \\sin(\\theta) g\\). To find the work done in pushing the mass an infinitesimal distance along the ramp we need to know the instantaneous length of the ramp. This is potentially confusing to the reader since we’ve already said that the distance is infinitesimal. As you know, infinitesimal is different from zero. We will write \\(dx\\) as an infinitesimal increment along the floor, but the zoomed-in length \\(dL\\) of the corresponding part of the ramp is the hypotenuse of a right triangle where one leg has length \\(dx\\) and the other leg has length \\(\\partial_x f(x) dx\\): slope times distance.\n\n\n\n\n\n\n\n\n\nThe hypotenuse of the infinitesimal segment of the ramp has length \\(dL = \\sqrt{\\strut dx + \\partial_x f(x) dx}\\), or \\(dL = \\sqrt{\\strut 1 + \\partial_x f(x)}\\ dx\\). Things are a bit simpler if we write \\(dL\\) in terms of the slope angle \\(\\theta(x)\\). Since \\(dx = \\cos(\\theta(x)) dL\\), we know \\(dL = dx/\\cos(\\theta(x))\\). Consequently the infinitesimal of work is \\[dW \\ = \\ m g \\frac{\\sin(\\theta(x))}{\\cos(\\theta(x))}\\ dx\\  = \\ m g \\tan(\\theta(x)) dx \\ .\\]\nThe total work is the accumulation of \\(dW\\) over the extent of the ramp. In other words, \\[\\int_a^b m g \\tan(\\theta(x))\\ dx\\ = \\ \\int_a^b m g \\tan(\\arctan(\\partial_x f(x)))\\ dx = \\int_a^b m g \\partial_x f(x) dx\\ ,\\] where we’ve used the formula \\(\\theta(x) = \\arctan(\\partial_x f(x))\\). From the “fundamental theorem of calculus” we know that\n\\[\\int_a^b m g\\ \\partial_x f(x)\\ dx \\ = \\ \\left.m g \\ f(x){\\Large\\strut}\\right|_a^b = mg \\left[\\strut f(b) - f(a)\\right] = mg h\\ .\\]\nWhat’s remarkable is that pushing the mass up the \\(f(x)\\)-shaped ramp involves an amount of work, \\(m g h\\), that does not depend on \\(f(x)\\), only on \\(f(b) - f(a)\\), the net height comprised by the ramp.\nWe haven’t yet said what this notion of work is good for and we’ve given no detailed justification for the definition of mechanical work as force times distance. You could imagine a dictatorial authority deciding to measure work as the square-root of force times distance squared. But … that particular measure is not going to make sense if we think about the dimension of the quantity. Force has dimension [force] = M L T-2. Square root of force times length squared would have dimension [sqrt(force) \\(\\times\\) length-squared] = M1/2 L5/2 T-2. The non-integer exponents mean that this is not a legitimate physical quantity.\nThe dimension of force-times-length are straightforward: [force \\(\\times\\) length] = M L2 T-2, that is, energy. The particular definition of work as force times length will make sense in the context of a more comprehensive mechanical theory of energy. The significance of energy itself is that, as a fundamental proposition of physics, the various forms of energy are interchangeable but conserved; energy is neither created nor destroyed, just moved around from one form to another and one place to another.\n\nNear the surface of the Earth, gravitational acceleration is approximately constant regardless of latitude or longitude. But gravity varies with distance \\(r\\) from the Earth’s center. Newton’s law of universal gravitation gives the force on an object of mass \\(m\\) due to the Earth’s gravity as\n\\[F = \\frac{m M_e G}{r^2}\\] where \\(M_e = 5.972 \\times 10^{24}\\) kg is the mass of the Earth and \\(G = 6.674 \\times 10^{-11}\\) N m2 / kg2 is the universal gravitational constant. The Earth’s radius is roughly \\(6,370,000\\) m, so the force on a 1 kg object near the surface of the Earth is \\(F = 1 \\text{kg} (5.972 \\times 10^{24} \\text{kg}) (6.674 \\times 10^{-11})/ (6.37 \\times 10^6 \\text{m})^2\\) N m2 kg-2. Carrying out the arithmetic and consolidating the units gives \\[F = 9.823 N\\] for the 1 kg object.\nSuppose we want to lift the 1 kg object from the Earth’s surface to 10000 km away, that is, to a distance of 1,6370,000 m from the center of the Earth. For the purpose of the example, we will ignore the gravitational force exerted by the Sun, Moon, planets, and other galaxies, etc. The work performed in the lifting is\n\\[\\int_{6.47\\times 10^6}^{16.47\\times 10^6} \\frac{1 \\text{kg}\\ M_e\\ G}{r^2}\\ dr = -\\left.  {\\Large\\strut}\\frac{1 \\text{kg}\\ M_e\\ G}{r}\\right|_{6.47\\times 10^6}^{16.47\\times 10^6} \\\\\\ \\\\\\ \\\\=\n-\\ 3.986 \\times 10^{14}\\left[\\strut \\frac{1}{16.47 \\times 10^6} - \\frac{1}{6.47 \\times 10^6}\\right] \\text{N m} \\\\\\ \\\\\\ \\\\= 37,405,840\\ \\text{J}.\\]\nA Newton-meter (N m) is also known as a Joule (J), a unit of energy. With 37,000,000 J, you could toast about 2000 pieces of bread. (A toaster uses about 300 W of power and takes about 60 seconds to process a slice of bread. \\(\\text{300 W} \\times \\text{60 s} = 18,000 \\text{J}\\)."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#energy",
    "href": "Manifestations/B4-mechanics.html#energy",
    "title": "52  Mechanics",
    "section": "52.2 Energy",
    "text": "52.2 Energy\nMechanical work, as discussed in the previous section, is a form of energy. When we lift a object, we put energy into the object. But we cannot say from examining the object how much work was done to place it on the table. The amount of work depends on how the object came to be on the table: lifted from the floor (positive work; force is positive upward, displacement is also positive upward) or perhaps lowered from a helicopter (negative work: force exerted by the cable is positive upward but the displacement is downward, therefore negative). We might call the work energy latent, the word meaning “unobservable,” “hidden,” “concealed,” “dormant.” To have an operational meaning, the work-energy that we assign to an object at rest must be with respect to some “ground state.” A convenient ground state here is to imagine the object resting on the ground. The assigned energy will then be the work that would have to be performed to raise the object to table height. Once at table height, the energy is again latent.\nHow then to measure the work energy that is latent in the object resting on the table? The idea is to return the object to its ground state, which we could do by lowering it—a negative displacement—to the ground, measuring the force needed to support the object (upward, so positive) and multiplying this by the displacement.\nAnother idea for measuring the latent energy is to let the object fall freely back toward its ground state and see what changes about the object. Perhaps you have already caught on to what will happen: the object’s speed increases steadily until the instant before it hits the ground.\n“Latent” is an apt but unusual word to express the energy imbued in the object resting on the table. We might equally say that the energy is “associated with position (at the height the table),” or we could call it “gravitational energy.” The term that is generally used is a near synonym of “latent.” We call the energy of the stationary object on the table potential energy. More precisely it can be called gravitational potential energy to distinguish it from the potential energy created by other forms of work, for instance pulling apart magnets or electric charges or compressing a gas into a cylinder.\nThere is also a form of energy associated with motion. We could call this “energy of motion,” but the conventional term is kinetic energy. (A dictionary definition of “kinetic” is “relating to or resulting from motion.” so we might as well say simply that kinetic energy is “energy relating to motion.)\nVelocity is a good way to observe motion. We can use dimensional analysis to anticipate how velocity and kinetic energy are related. Recall that energy has dimension M L2 T-2 and velocity has dimension L/T. Consequently, if an object’s kinetic energy at any instant stems from its mass and its velocity, then the energy must be mass times velocity squared, perhaps multiplied by a scalar, that is:\n\\[E_{kinetic} = \\alpha\\, m v^2\\ .\\]\nTo find the scalar \\(\\alpha\\), we can use calculus and accumulation. We know that the acceleration of a free-falling object due to gravity is \\(-g\\) (where the negative sign reflects the downward direction). Starting from rest (that is zero velocity so zero kinetic energy) the newly released mass will have a velocity that is the accumulated acceleration over time. In other words:\n\\[v(t) = \\int_0^t - g\\ dt = -\\left.g \\ t{\\large\\strut}\\right|_0^t = -g\\ t\\ .\\]\nCorrespondingly, the position at time \\(t\\) will be the accumulated velocity: $$x(t) = x(t=0) + _0^t v(t) dt \\ =\nh + _0^t -g t dt \\ = h - .g t^2{\n}|_0^t   =   h - g t^2  .$$ The mass reaches the ground at time \\(t_g\\) such that \\(h - \\frac{1}{2} g\\ t_g^2 = 0\\). Solving this for \\(t_g\\) gives \\(t_g = \\sqrt{\\strut 2 h/g}\\).\nNow that we know the time when the object reaches its ground state, we can calculate the velocity at that instant:\n\\[v(t_g) = -g\\ t_g = - g\\ \\sqrt{\\strut 2 h / g} = - \\sqrt{\\strut 2 g h}\\]\nAs the object reaches its ground state, its gravitation potential energy is zero (because it is at the ground state) and, since total energy is conserved, the kinetic energy will be the same size as the potential energy at \\(t=0\\) when the object was released from the table, that is\n\\[E_{kinetic}(t_g) = \\alpha\\ m\\ v(t_g)^2 =\n= \\alpha\\ m \\left(\\sqrt{\\strut 2 g h\\ }\\ \\right)^2 = \\\\\\ \\\\2\\, \\alpha\\, m\\, g\\, h\\  = m\\, g\\, h = E_{potential}(t=0)\\]\nSolving \\(2 \\alpha\\ m\\,g\\,h = m\\,g\\,h\\) gives \\(\\alpha = \\frac{1}{2}\\). Thus, the kinetic energy as a function of mass \\(m\\) and velocity \\(v\\) is \\(\\frac{1}{2} m\\, v^2\\).\n\nIn the previous section, we calculated the potential energy of a 1 kg object at an altitude of 10,000 km above the Earth’s surface: 37,405,840 J. How fast would the 1 kg object need to be moving to have this much kinetic energy?\n\\[\\frac{1}{2} (1 \\text{kg}) v^2 = 37,\\!405,\\!840 \\text{J} = 37,\\!405,\\!840 \\ \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\]\nSolving for \\(v\\) we get \\(v^2 = 2 \\times 37,\\!405,\\!840 \\text{kg}\\ \\text{m}^2\\ \\text{t}^{-2}\\ \\text{kg}^{-1}\\) or \\[v = 8649.4\\ \\text{m}/\\text{s}\\ ,\\] about eight-and-a-half kilometers per second.\n\n\nThe photograph (source) shows a simple exercise: holding a dumbbell out horizontally.\n\n\n\n\n\n\n\n\n\nAs anyone who does this exercise can tell you, even when there is no movement of the dumbbell, there is a strong sense of work being done. Your muscle fatigues and, for most people, the dumbbells can be held in place for only a short time.\nWe’ve said that mechanical work always involves motion; no motion, no work. So how come the exercise feels like work even though the hands do not move?\nTo perform the exercise, you contract the muscles of the shoulder and upper arm. There is no skeletal joint that can be locked in place (unlike, say, the knee). It is only the muscle force that holds the arms in place.\nOn the size scale that we normally perceive, it can appear that nothing is moving during the exercise. But zoom in to the molecular scale to see the action by which force is generated by muscle. The functional unit of muscle force involves two proteins, actin and myosin, that interact in a complicated way. The animation (from the online textbook by Michael D. Mann, The Nervous System in Action, chapter 14) shows the situation. The “head” of a myosin unit (red) acts like an oar. It attaches to a site on the actin molecule (orange) causing the head to contract and pull on the actin. Once contracted, a molecule of ATP (green sphere) binds to the myosin, releasing the head and preparing it for another stroke. ATP is an organic molecule that serves as a primary energy carrier and is found in all known forms of life. Transformation of ATP to ADP releases the energy. The ADP is then cycled, though other metabolic processes, back into ATP. This happens rapidly. Humans recycle approximately their own body weight in ATP each day.\n\n\n\n\n\nFigure 52.2: Animation of the generation of force by the interaction of actin and myosin, from The Nervous System in Action.\n\n\n\n\nWhen muscle is under tension, the actin can slip back in between strokes of the myosin head. Thus, a constant-length muscle in tension on a macroscopic scale is steadily consuming energy, in much the same way as an oarsman on an anchored boat can do work via the movement of oars against the water even when the boat itself is not moving."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#momentum",
    "href": "Manifestations/B4-mechanics.html#momentum",
    "title": "52  Mechanics",
    "section": "52.3 Momentum",
    "text": "52.3 Momentum\nIn the previous sections we looked at force \\(\\times\\) distance. Dimensional analysis showed that [force \\(\\times\\) distance] = energy and, in the setting of lifting an object and letting it fall back toward its ground state, we traced out the conversion of the energy of position (“potential energy”) into the energy of velocity (“kinetic energy”).\nNow consider a somewhat different quantity: force \\(\\times\\) time. Dimensional analysis gives\n\\[\\underbrace{M^1 L^1 \\ T^{-2}}_\\text{[force]}\\  \\times\\ \\underbrace{T}_\\text{[time]} = \\underbrace{M^1}_\\text{[mass]} \\underbrace{L^1 T^{-1}}_\\text{[velocity]} \\]\nThe product of force times time is dimensionally equivalent to the product of mass times velocity. The quantity is called momentum. Newton’s second law of motion, often written in terms of acceleration, \\(F = m a\\), is more fundamentally written in terms of momentum: \\(F = \\partial_t\\, m\\, v\\). The conservation of momentum refers to the situation when outside forces on a system are nil. In such case, momentum of the system does not change with time; momentum is constant or “conserved.”\nAn example of such a system is a deep-space probe, sufficiently far from other matter that gravitational force is negligible. to speed up or slow down (or turn), the probe is made to throw out fast moving molecules of burnt fuel. These particles have “new” momentum, but since momentum of the whole system is conserved, the body of the probe gains “new” momentum in the opposite direction. This is the operating principle of the rocket engine.\n\n\n\n\n\nFigure 52.3: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air.\n\n\n\n\n\n\n\nFigure 52.4: Left: A turbojet engine uses air for combustion and emits a relatively low amount of mass at high velocity. Right: A turbofan engine uses a fan blade (1) to convert some of the combustion energy into a large mass of relatively slow velocity, unburnt air.\n\n\n\n\nAircraft jet engines work in a similar matter, burning fuel to create energy. Whereas the force generated by a rocket engine is entirely produced by the newly created momentum of the burnt fuel, aircraft engines have an additional material to work with: air. The earliest jet engines, turbojet engines, were small in diameter, bringing in air mainly as a fuel for combustion. (?fig-jet-engines (left)1 Today’s more efficient engines are large diameter: turbofan engines. (?fig-jet-engines (right)2) In addition to using air for combustion, they use large fan blades to convert the energy of combustion into a large mass of relatively slowly moving, uncombusted air. This moving air carries momentum; more than that contained in the fast moving particles generated directly through combustion."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#sec-center-of-mass",
    "href": "Manifestations/B4-mechanics.html#sec-center-of-mass",
    "title": "52  Mechanics",
    "section": "52.4 Center of mass",
    "text": "52.4 Center of mass\nIn considering a physical object of extended shape, it can be a great simplification to be able to treat the whole extended object as if it were a simple point object at a single location. For instance, Figure 52.5 imagines a space probe (orange dot) coasting through the edge of a galaxy.\n\n\n\n\n\n\n\n\nFigure 52.5: An imagined space probe (orange dot) on the outer edges of a galaxy.\n\n\n\n\nWhat is the gravitational attraction of the galaxy on the probe? One way to find this is by adding up the individual gravitational attractions of the individual stars. Another is to find the center of mass of the galaxy and calculate the force as if all the mass were at that point. The two calculations give the same answer.\nFor the galaxy, the center of mass is located at a point \\((\\bar{x},\\bar{y})\\) where \\[\\bar{x} \\equiv \\sum_\\text{galaxy} m_i x_i\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\equiv \\sum_\\text{galaxy} m_i y_i\\]\n\n\n\n\n\n\n\n\nFigure 52.6: An irregular shape used in the example. The \\((x,y)\\) coordinates of closely spaced points on the boundary are available as Blob1 in the sandbox software.\n\n\n\n\nFor a continuous shape, such as in Figure 52.6 (left) we can describe the center-of-mass calculation as an accumulation of the mass-density function \\(\\rho(x, y)\\) over the entire shape \\(S\\). The mass of the object is the accumulation of mass-density itself\n\\[M = \\int_\\text{S} \\rho(x,y)\\ d\\text{S}\\]\nwhile the components of the center of mass are the accumulation of \\(x\\ \\rho(x,y)\\) and \\(y\\ \\rho(x,y)\\), that is: $$\n{x} =  x (x,y) d / M\\ {y} =  y (x,y) d / M\n$$ where \\(S\\) refers to the whole object and \\(d\\)S is a differential of the object, that is, a tiny piece of the object.\nThere are many ways to split an object up into differentials so that they can be accumulated to give the whole integral. One simple way, shown in Figure 52.6 (right), is to divide the object into a set of discrete, non-overlapping, adjacent rectangles (or cubes for a three-dimensional object). Then, as with adding up the stars, just add up \\(x \\rho(x, y) d\\)S or \\(y \\rho(x,y) d\\)S contained in each of the rectangular \\(d\\)A regions. For the rectangle located at $(x_i, y_i), the mass \\(m_i\\) will be \\(m_i = \\rho(x_i, y_i) d\\)S: density times area of each rectangle. This turns the integrals in Eq. @ref(eq:cm-integral) into a sum:\n\\[\\bar{x} \\approx \\sum_\\text{rectangles} m_i x_i/ M\\ \\ \\ \\text{and}\\ \\ \\ \\ \\bar{y} \\approx \\sum_\\text{rectangles} m_i y_i / M\\] where \\[M = \\sum_\\text{rectangles} m_i\\ .\\]\n\n\n\n\n\nFigure 52.7: A continuous shape can be approximated by a set of rectangles within the borders of the shape. Integrating over the shape is a matter of adding up across all of the rectangles the relevant quantity for each rectangle.\n\n\n\n\nFor the center of mass calculation, the relevant quantity for \\(\\bar{x}\\) for each rectangle is the mass times the \\(x\\)-position. Similarly, for \\(\\bar{y}\\) the relevant quanty is the mass times the \\(y\\)-position.\n\n\n\n\n\nFigure 52.8: For the \\(y\\)-component of the center of mass (left panel), the \\(x\\)-coordinate of each rectangle is irrelevant. It is as if all the rectangles were moved to \\(x=0\\). Similarly for the \\(x\\)-component of the center of mass (right panel).\n\n\n\n\n\nCompute the center of mass of the object Blob1 shown in Figure 52.6, assuming the mass-density \\(\\rho(x,y) = 10\\).\nThe mass of the object is \\[M = \\int_\\text{Blob1} \\rho(x, y)\\, dA\\] The \\(x\\)-component of the center of mass is\n\\[\\bar{x} = \\int_\\text{Blob1} x \\rho(x, y)\\, dA / M\\]\nand similarly for \\(\\bar{y}\\).\nTo find the center of mass, we first need to know the total mass of the object. We will carry out the calculation by dividing the object into a series of rectangles, computing the mass of each rectangle, then adding together the masses. The R/mosaic function box_set() takes as input the density function, a data frame with points on the boundary of the object, and a size for the boxes, which we will set to \\(dx=0.1\\).\n\nBoxes <- box_set(10 ~ x + y, Blob1, dx=0.1)\n\nGive this command in a sandbox and look at the resulting data frame Boxes. Each row is one box. The x and y columns give the location of the center of that box, dx and dy are the lengths of the box sides in the \\(x\\) and \\(y\\) directions. The value ofthe function being accumulated is in the column labelled .output. column dA gives the area of each box (which is simply \\(dA = dx\\, dy\\)).\nAs the notation \\[\\int_\\text{Blob1} \\rho(x, y) dx dy\\] suggests, to accumulate the results for the individual boxes we just multiply the .output. by dA and sum.\n\nmass <- with(Boxes, sum(.output. * dA))\n\n\n## [1] 67.3\n\nComputing the \\(x\\)-component of the center of mass, \\(\\bar{x}\\), is much the same but now the function being integrated is \\(x \\rho(x,y)\\) instead of just \\(\\rho(x,y)\\):\n\nBoxes2 <- box_set(10*x ~ x + y, Blob1, dx=0.1)\nxbar <- with(Boxes2, sum(.output. * dA)) / mass\n\n\n## [1] -0.1543015\n\nThe \\(y\\) component of the center of mass, \\(\\bar{y}\\) is computed almost identically, but substituting 10*y ~ x & y as the function to be integrated. In the next line, we will tell box_set() to do the summation over all the boxes directly, instead of our having to do it with the with(..., sum(.output. * dA)) command.\n\nybar <- box_set(10*y ~ x + y, Blob1, dx=0.1, sum=TRUE) / mass\n\n\n## [1] -0.2371817\n\n\nRecall that the summation over the boxes provides an approximation to the integral. The quality of the approximation depends on the boxes being small enough. It is responsible to check the result by using smaller box size:\n\nybar <- box_set(10*y ~ x + y, Blob1, dx = 0.01, sum=TRUE) / mass\nybar\n## [1] -0.2323201\nbox_set(10*y ~ x + y, Blob1, dx = 0.001, sum=TRUE) / mass\n## [1] -0.2322872\n\nFrom this, we conclude that a box size dx = 0.01 gives 4 digits precision, but dx = 0.1 was not small enough.\nRepeat the calculation for \\(\\bar{x}\\) to get the same precision: ::: {.cell layout-align=“center” fig.showtext=‘false’}\nxbar  <- box_set(10*x ~ x + y, Blob1, dx = 0.01, sum=TRUE) / mass\n\n\n## [1] -0.1513999\n\n\nThere is more than one way to describe the perimeter of an object, and the manner of integration has to be selected to match the description.\nConsider this shape that might be the design of a panel in a large sculpture. The panel will be cut out of 3mm thick sheet aluminum \\(x\\) and \\(y\\) are given in meters. In order for the panel to be balanced, it will be mounted at its center of mass\n\n\n\n\n\n\nFigure 52.9: A panel to locate center of mass\n\n\n\nThe shape is defined by two functions, \\(f(x)\\) and \\(g(x)\\), one of which sets the top edge and the other the bottom edge. The side edges are defined by the leftmost and rightmost values of \\(x\\). Here, that is \\(x_\\text{left} = - 1.5\\) and \\(x_\\text{right} = 4.0\\).\nThe area of the object can be found using the integration techniques from Block 3. For the purpose of finding the center of mass, we need to calculate the mass of the object. For 3mm sheet aluminum the density is about 8.1 kg/m2. Here, that is simply \\[\\text{mass} = \\int_{-1.5}^{4.0} 8.1 \\left[\\strut f(x) - g(x)\\right] dx \\approx 880 \\text{kg}\\ .\\]\nWhat about the center of mass? Because the shape is not described as a set of boxes, as we did earlier in this section, we need a way to perform the accumulation that uses only the information in the functions.\nThe differential \\(8.1 \\left[\\strut f(x) - g(x)\\right] dx\\) gives the mass of each vertical slice of the object, several of which are shown in \\(\\color{magenta}{\\text{magenta}}\\) in ?fig-cm-fun-diff.The tops and bottoms of those slices don’t align exactly with the boundaries of the object. That is because we’ve drawn them at a finite width so that you can see them. But the actual differentials being accumulated will have negligible width, and so will fit exactly.\n\n\n\n\n\nFigure 52.10: The panel can be divided into vertical slices, a few of which are shown here. The vertical mid-point of each slice is marked with a blue dash. Accumulating the slices’ mid-point coordinates times the slices’ mass, and dividing by the panel’s mass, gives the \\(y\\)-component of the center of mass.\n\n\n\n\nThe horizontal positions of the vertical slices are given by \\(x\\). The \\(x\\)-component of the center of mass of each individual vertical slice will be\n\\[x \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx\\ .\\]\nThe center of mass of the entire object will be the accumulation\n\\[\\bar{x}= \\frac{1}{\\text{mass}}\\int_{-1.5}^{4.0} x\\ \\text{density} \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx \\approx 1.72 \\text{m}\\ .\\]\nFinding the \\(y\\)-component of the center of mass could be done in a similar way, by constructing horizontal slices. However, we would have to calculate the functions \\(\\text{left}(y)\\) and \\(\\text{right}(y)\\) that bound each slice.\nAn easier way is to find the vertical center of each slice. For a slice at position \\(x\\), the vertical center is \\[y_{\\text{mid}}(x) \\equiv\\left[\\strut \\text{top}(x) + \\text{bottom}(x)\\right]/ 2\\ ,\\] the average of the top and bottom positions. (These are marked in \\(\\color{blue}{\\text{blue}}\\) in Figure 52.10.) The \\(y\\)-component of the center of mass is \\[\\begin{eqnarray}\n\\bar{y} &=& \\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ y_\\text{mid}(x)\\ \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx = \\\\\n&=&\\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ \\frac{\\left[\\strut \\text{top}(x) + \\text{bottom}(x) \\right]}{2}\\ \\left[\\strut \\text{top}(x) - \\text{bottom}(x)\\right] dx =\\\\\n&=&\\frac{1}{\\text{mass}} \\int_{-1.5}^{4.0} \\text{density}\\ \\frac{\\left[\\strut \\text{top}(x)^2 - \\text{bottom}(x)^2 \\right]}{2}\\ \\approx -5.43 \\text{m}\\ .\n\\end{eqnarray}\\]\nThe center of mass, \\((x=1.72, y=-5.43)\\), is plotted as \\(\\color{blue}{\\Large\\mathbf{\\text{+}}}\\) on the object."
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#angular-momentum-and-torque",
    "href": "Manifestations/B4-mechanics.html#angular-momentum-and-torque",
    "title": "52  Mechanics",
    "section": "52.5 Angular momentum and torque",
    "text": "52.5 Angular momentum and torque\nThe relationship between force and momentum is familiar: \\[F = \\partial_t\\, m\\, v =\\ \\underbrace{m \\ \\partial_t\\  v}_\\text{if mass is constant}\\ .\\] Of course, the derivative of velocity with respect to time is also called “acceleration.”\nConsider the following situation. A space probe is being acted on by a constant force, as in Figure 52.11. The mass of the probe is \\(m\\), the thrust from the rocket engine provides the force \\(F\\). Starting from velocity \\(\\partial_t y(t=0)\\) and position \\(y(t=0) = 0\\), the thrust produces an acceleration \\(\\partial_{tt} y(t) = F/m\\). Integrating the acceleration gives the velocity as a function of time\n\\[\\partial_t y(t) = \\frac{F}{m} t + C\\ .\\]\n\n\n\n\n\n\nFigure 52.11: A space probe accelerating along a linear course. The position at time \\(t\\) can be written as \\(y(t)\\) or as $ heta(t)$.\n\n\n\nThe function \\(y(t)\\) is not the only way to represent where the probe is as a function of \\(t\\). Suppose that the probe is being observed by a telescope which measures the angle \\(\\theta(t)\\) with respect to the equatorial plane. If the distance to the probe is \\(D(t)\\), then the pair \\(\\left(\\strut\\theta(t), D(t)\\right)\\) gives the position of the probe. As \\(y(t)\\) increases, so do \\(\\theta(t)\\) and \\(D(t)\\).\nWe know the laws of motion in terms of \\(y(t)\\). Can we translate these laws to an expression in terms of \\(\\theta(t)\\) and \\(D(t)\\)? That is, can we find the function \\[\\partial_{t} \\theta(t) = {\\Large ?}\\] If we can find the laws of motion in terms of \\(\\theta(t)\\) and \\(D(t)\\), we will have a way to describe the motion of spinning bodies.\n\n\n\nThe derivation of \\(\\partial_{t} \\theta(t)\\) will not be obvious, but you will be able to see how calculus operations come into play.\nThree points in the diagram describe a right triangle: the probe’s position at \\(t=0\\), the center of the planet, and the probe’s position at time \\(t\\). The length of the horizontal leg of the triangle is \\(D(t=0)\\) which not a function of time, so we will drop the unnecessary parentheses and write it as \\(D_0\\). The vertical leg has length \\(y(t)\\), and the hypotenuse has length \\(D(t)\\). The Pythagorean theorem tells us that \\[D(t)^2 = y(t)^2 + D_0^2\\ .\\]\nStep 1: Differentiate both sides with respect to \\(t\\): \\[\\partial_t \\left[\\strut D(t)^2\\right] = \\partial_t \\left[\\strut y(t)^2\\right] \\ . \\] Using the chain rule and the fact that \\(D_0\\) does not depend on \\(t\\), gives\n\\[2\\, D(t)\\, \\partial_t D(t) = 2\\, y(t)\\ \\partial_t y(t)\\ \\ \\implies\\ \\ \\partial_t y(t) = \\frac{D(t)}{y(t)}\\,\\partial_t D(t)\\ .\\]\nStep 2: Trigonometry allows us to see a relationship among the functions \\(y(t)\\), \\(\\theta(t)\\), and \\(D(t)\\):\n\\[y(t) = D(t) \\sin\\left(\\strut\\theta(t)\\right) \\ .\\]\nPlugging this form of \\(y(t)\\) into the equation for \\(\\partial_t y(t)\\) in Step 1 produces \\[\\partial_t y(t) = \\frac{1}{\\sin(\\theta(t))} \\partial_t D(t)\\] and\n\\[D_0 = D(t) \\cos\\left(\\strut\\theta(t)\\right)\\ \\ \\implies\\ \\ D(t) = \\frac{D_0}{\\cos\\left(\\strut\\theta(t)\\right)}\\]\nStep 3: Another fact from trigonometry is that \\[D(t) = D_0/\\cos(\\theta(t))\\ .\\] Differentiating both sides (chain rule again!) with respect to \\(t\\) gives another form for \\(\\partial_t D(t)\\):\n\\[\\partial_t D(t) = D_0\\, \\partial_t \\left(\\frac{1}{\\cos\\left(\\strut\\theta(t)\\right)}\\right) = D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\]\nStep 4: Combining the results from Steps 1 and 3 gives\n\\[\\partial_t y(t) =  \\frac{1}{\\sin\\left(\\strut\\theta(t)\\right)}D_0 \\frac{\\sin\\left(\\strut\\theta(t)\\right)}{\\cos\\left(\\strut\\theta(t)\\right)^2}\\, \\partial_t \\theta(t)\\ .\\]\nCancelling out the \\(\\sin(\\theta(t))\\) terms and remembering that \\(\\partial_t y(t) = \\frac{F}{m} t\\) gives\n\\[\\frac{F}{m} t = \\frac{D_0}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) \\]\nMultiplying both sides by \\(D_0\\) and recalling that \\(D(t) = D_0/\\cos(\\theta(t))\\) we arrive at\n\\[\\frac{F D_0}{m} t = \\frac{D_0^2}{\\cos\\left(\\strut \\theta(t)\\right)^2}\\, \\partial_t\\theta(t) = D(t)^2 \\partial_t \\theta(t)\\ . \\]\nAgain re-arranging to find \\(\\partial_t\\, \\theta(t)\\):\n\\[\\partial_t\\,\\theta(t) = \\frac{F\\, D_0}{m D(t)^2}\\ t\\ .\\]\nTo summarize, we have two equivalent expressions for the dynamics of the space probe:\n\\[\\partial_t y(t) = \\frac{\\overbrace{\\ F}^\\text{force}}{\\underbrace{M}_\\text{mass}} t \\ \\ \\text{and}\\ \\ \\partial_t \\theta(t) = \\frac{\\overbrace{F\\, D_0}^\\text{torque}}{\\underbrace{m D(t)^2}_\\text{moment of inertia}}\\ t\\ .\\]\nIn rectangular \\((x,y)\\) coordinates, the velocity is the accumulation of force divided by mass: the usual statement of Newton’s second law of motion. In the angular coordinates \\((\\theta, D)\\) the angular velocity is the accumulation of torque divided by ***moment of inertia.\nThe angular coordinate representation is helpful when studying the rotation of objects. To illustrate, imagine a different configuration for the system than that in in Figure 52.11 where the space probe was free to accelerate in a straight line. Instead, suppose the rocket is mounted on a carousel, that is a wheel whose axle goes through the center as in Figure 52.12.\n\n\n\n\n\n\nFigure 52.12: The space probe mounted on a rigid wheel that can spin around its center.\n\n\n\nIn the rocket-on-wheel configuration, \\(D(t)\\) is a constant; the rocket stays the same distance from the center. Therefore, the moment of inertia is \\(m D_0^2\\). Following the previous formula, \\[\\partial_t \\theta(t) = \\frac{F D_0}{m D_0^2} t\\] which is easily differentiated to give the angular acceleration \\[\\partial_{tt} \\theta(t) = \\frac{F D_0}{m D_0^2}\\ .\\]\nIn a typical wheel, there is mass density throughout the wheel, not just at distance \\(D_0\\). To find the moment of inertia of such a distributed mass system, break the wheel down into small pieces and find the moment of inertia due to each bit. Then accumulate the pieces’ moments of inertia to find the total moment of inertia:\n\\[\\text{moment of inertia} = \\int_\\text{wheel} \\rho(x,y) \\left(\\strut x^2 + y^2\\right) d \\text{wheel}\\ .\\]\n\nCompute the moment of inertia of Blob1.\nIt is not enough to say, “compute the moment of inertia.” We also have to specify what is the reference location—the wheel axle in the configuration. We will first do the calculation around the center of mass \\((\\bar{x}, \\bar{y})\\) which we computed earlier as xbar and ybar:\n\n# moment of inertia\nbox_set(10*((x - xbar)^2 + (y-ybar)^2)~ x + y, \n        Blob1, dx = 0.01, sum=TRUE) \n## [1] 76.67827"
  },
  {
    "objectID": "Manifestations/B4-mechanics.html#exercises",
    "href": "Manifestations/B4-mechanics.html#exercises",
    "title": "52  Mechanics",
    "section": "52.6 Exercises",
    "text": "52.6 Exercises\n\nExercise 53.17\nConfirm the calculation of the center of mass of the panel shown in Figure 52.9. The left edge of the panel is at -1.5 m, the right edge at 4.0 m. The functions describing the top and bottom edges of the panel are\n\ntop <- rfun(~ x, seed=120)\nbottom <- rfun(~ x, seed=2894)\n\nA. Calculate the area of the panel. The coordinates have units of meters.\nB. Calculate the mass of the panel. The density of the sheet aluminum is 8.1 kg/m2.\nC. Calculate the \\(x\\)-component of the center of mass.\nD. Calculate the \\(y\\)-component of the center of mass."
  },
  {
    "objectID": "R-mosaic-setup.html",
    "href": "R-mosaic-setup.html",
    "title": "Setting up R/mosaic",
    "section": "",
    "text": "Use the “MOSAIC Calculus Sandbox” web app. Using the platform via the sandbox involves zero set-up. Just follow this link to the sandbox. The sandbox is the easiest way to get started, but can be slow.\nUse rstudio.cloud. Usually, your instructor asks you to set up your own account at <rstudio.cloud> and may give you a link to a “workspace” that has everything you need. This platform provides full features for using R, including document editing.\nYour instructor may give you an account on an institution-specific “RStudio server.”\nInstall R and RStudio on your own laptop. There are many online videos showing how to do this installation.\n\nIf you use method (4) and in some cases (2) or (3), you need to do a bit more installation. First, install some software that provides background support for {mosaicCalc}. Do this by opening RStudio (or plain R if you are using that) and copy the following command into your R console. (Many of the online videos show what’s meant by a “console.”)\ninstall.packages(c(\"remotes\", \"knitr\", \"ggplot2\", \"rmarkdown\"))\nSecond, install {mosaicCalc} itself. In this process of this installation, you will be asked a question: “Do you want to install from sources …?” Answer no.\ninstall.packages(\"mosaicCalc\")\nInstallation is a one-time process, although if you switch to a new computer you will have to repeat the installation on that computer.\nNOTE: Your instructor might ask you to update to the latest version of {mosaicCalc}. You can do this with the following command:\nremotes::install_github(\"ProjectMOSAIC/mosaicCalc\", build_vignettes = TRUE)\nWith {mosaicCalc} and its allies installed, you’re ready to start. Open R or RStudio to commence an R session. As your first command, type\nlibrary(mosaicCalc)\nwhich tells R to use the {mosaicCalc} software.\nYou will need to give the library(mosaicCalc) command each time you open up R or RStudio. That might be once a day, once a week, depending on how often you close the R or RStudio app on your computer."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MOSAIC Calculus",
    "section": "",
    "text": "Calculus is the set of concepts and techniques that form the mathematical basis for dealing with motion, growth, decay, and oscillation. The phenomena can be as simple as a ball arcing ballistically through the air or as complex as turbulent airflow over a wing generating lift. Calculus is used in biology and business, chemistry, physics and engineering. It is the foundation for weather prediction and understanding climate change. It is the basis for the algorithms for heart rate and blood oxygen measurement by wristwatches. It is a key part of the language of science. The electron orbitals of chemistry, the stresses of bones and beams, and the business cycle of recession and rebound are all understood primarily through calculus.\nCalculus has been central to science from the very beginnings. It is no coincidence that the scientific method was introduced and the language of calculus was invented by the same small group of people during the historical period known as the Enlightenment in the late 17th century. Learning calculus has always been a badge of honor and an entry ticket to professions. Millions of students’ career ambitions have been enhanced by passing a calculus course or thwarted by lack of access to one.\nIn the 1880s, a hit musical featured “the very model of a modern major general.” One of his claims for modernity: “I’m very good at integral and differential calculus.”\n\n\n\n\n\n\n\n\nhttps://www.youtube.com/embed/Rs3dPaz9nAo\n\nWhat was modern in 1880 is not modern anymore. Yet, amazingly, calculus today is every bit as central to science and technology as it ever. Indeed, calculus remains central to fields that were not even imagined in 1880, such as logistics, economics, and data science. One reason is that science, engineering, and society have now fully adopted the computer for almost all aspects of work, study, and life. The collection and use of data is growing dramatically. Machine learning has become the way human decision makers interact with such data.\nThink about what it means to become “computerized.” To take an everyday example, consider video. Over the span of a human life, we moved from a system which involved people going to theaters to watch the shadows recorded on cellulose film to the distribution over the airwaves by low-resolution television, to the introduction of high-def broadcast video, to on demand streaming from huge libraries of movies. Just about anyone can record, edit, and distribute their own video. The range of topics (including calculus) on which you can access a video tutorial or demonstration is incredibly vast. All of this recent progress is owed to computers.\nThe “stuff” on which computers operate, transform, and transmit is always mathematical representations stored as bits. The creation of mathematical representations of objects and events in the real world is essential to every task of any sort that any computer performs. Calculus is a key component of inventing and using such representations.\nYou may be scratching your head. If calculus is so important, why is it that many of your friends who took calculus came away wondering what it is for? What’s so important about “slopes” and “areas” and how come your high-school teacher might have had trouble telling you what calculus is for?\nThe disconnect between the enthusiasm expressed in the preceding paragraphs and the lived experience of students is very real. There are two major reasons for that disconnect, both of which we tackle head-on in this book.\nFirst, teachers of mathematics have a deep respect for tradition. Such respect has its merits, but the result is that almost all calculus is taught using methods that were appropriate for the era of paper and pencil—not for the computer era. As you will see, in this book we express the concepts of calculus in a way that carries directly over to the uses of calculus on computers and in genuine work.\nSecond, the uses of calculus are enabled not by the topics of Calc I and Calc II alone, but the courses for which Calc I/II are preliminary: linear algebra and dynamics. Only a small fraction of students who start in Calc I ever reach the parts of calculus that are the most useful. Fortunately, there is a large amount of bloat and rote in the standard textbook topics of Calc I/II. This can be removed to make room for the more important topics, as we try to do in this book.\nYou will want to use a computer to follow this book. Your instructor might want you to set up the required software in a way that fits the resources and course-support systems of your institution. Alternatively, you can set up what you need for free on a standard laptop computer or even use a tablet with a keyboard. Instructions for this are given in Appendix ?sec-software-installation.\nThe computer language used in this book is R. This is a mainstream language in high demand by employers in many field. The small amount of R that you need to learn for this book will open doors to much greater possibilities. We have augmented R with a widely used package, {mosaic}, that simplifies access to calculus-related operations.\n\n\n\nThe “MOSAIC” in the book’s title refers to a movement in undergraduate mathematics to integrate Modeling, Statistics and data science, Computing, and Calculus. Skill in all these areas is needed for successful work in the technical and scientific world. Traditionally, teaching does not honor the strong links among these areas and ignores the advantages of teaching them in a unified way. Indeed, modeling, though often mentioned in calculus textbook blurbs, is hardly taught at all. Introductory statistics courses, even those with a formal pre-requisite of calculus, do not draw on calculus concepts beyond the mention of “area under a curve.” Few and far between are introductory computing courses that reinforce calculus and statistics topics, or calculus courses that develop and build on computing and data skills.\nThe isolation of mathematical calculus from disciplines that ought to be considered allies leads to a devastating gap in the education of students. The half-life of a student in a calculus sequence is, roughly speaking, one course. (The decay in participation starts in algebra and trigonometry.) The result is that only a small fraction of students see relevant mathematics of multiple variables and hardly any encounter the powerful concepts of spaces, vectors, and matrix factorizations traditionally reserved for a junior-year linear algebra course. Contemporary statistical modeling techniques, including machine learning, draw heavily on a small core of linear-algebra topics.\nThe design of the mosaic serves the goal of providing for all students access to a broad, directly useful education in the mathematical sciences. One component of access is keeping the program small enough to fit in with a plausible student schedule. Our working definition of “small enough” is one-quarter of the first two years of university. Fitting within this envelope, students ought to achieve basic competence in computing, statistics, and calculus.\nCalculus provides opportunities to prepare students well for both modern statistics and computing. The most direct ties to statistics are modeling, functions of multiple variables, and concepts of linear spaces. The relevant links of calculus to computing are extensive and go both ways. To give but one example: It’s impractical for students to construct contour plots without a computer. With a computer at hand, students can learn about mathematical ideas such as gradients and iterative optimization. For instance, constrained optimization is hardly a topic of standard introductory calculus and Lagrange multipliers are mysterious even to many professors. The essential concepts become much clearer when they can be presented using graphical tools of contours and gradient fields.\nA book that attempts to build on the connections among historically distinct disciplines must also resolve inconsistencies in nomenclature and notation. We draw the instructor’s attention to some of these and the policies adopted in the book:\n\nVariable. In mathematics “variable” is used with many different reasons, in computing “variable” is used colloquially to mean “the name of an object,” and in statistics a “variable” refers to data: a column of a data frame or, more generally, a specific attribute of the units of observation that form the rows of the data frame. (See Section Section 7.1 for definitions of “data frame” and “unit of observation.”) We reserve “variable” to be used in the statistical sense. Consequently, a “function of several variables” becomes a “function with several inputs.”\nOutput. Evaluating a function, either a mathematically or on a computer, produces an output. Functions take inputs and produce outputs. Typical names for inputs are, following tradition, the last few letters of the alphabet: \\(t, u, v, w, x, y, z\\).\nFunction names. Functions always have a name. \\(f()\\), \\(g()\\), \\(h()\\) are the pronouns for discussing functions in general, but in specific applications functions often have more descriptive names, e.g. population() or elev() or risk(). The empty parentheses are a reminder that the thing being named is a function and not an input or parameter. Since \\(y\\) is used as an input name, we never use it for the name of a function or to identify the output of a function. So, \\(y=mx+b\\) is not an esteemed phrase in this book. Instead, when we want to define a straight-line function we write \\(g(x) \\equiv a x + b\\) or some other parameterization, for instance \\(g(x) \\equiv a (x - x_0)\\).\nSpecial inputs. Often, a problem or application context requires the identification of some special values for inputs to a function, for instance, argmaxes or zero crossings or starting time. These are often constructed by using an output name (often \\(t\\) through \\(z\\)) with a subscript or a non-numerical superscript as in \\(y^\\star\\).\nOutput (part 2). When we mean something like “the output of the function \\(f()\\) at its argmax,” we write \\(f(x_\\star)\\), or something similar. When we mean, “the output of function \\(f()\\) at some as yet unspecified input,” we write, naturally enough, \\(f(x)\\).\nFormulas. An expression like \\(ax + b\\) is a formula. One of the most common ways to define a function is by using a formula. But creating a function from a formula requires some special syntax, as demonstrated earlier with \\(g(x) \\equiv a x + b\\). The names used within the parentheses on the left side of \\(\\equiv\\) are the input names. Other symbols in the formula are called parameters.\nTilde expression. We use the R language in this book. Those familiar with R know that there is a special kind of expression called a “formula,” for instance a*x + b ~ x. One of the main uses for R formulas is to represent a mathematical formula when creating a function. “Formulas representing formulas” can lead to confusion. We address this by violating the technical vocabulary of R and calling an expression like a*x + b ~ x a “tilde expression.” This name properly draws attention to the ~ (“tilde”) character that is an essential component to R-language formulas. A typical use for a tilde expression is to create a computer version of a function. The computer version of \\(g(x) \\equiv a x + b\\) is g <- makeFun(a*x + b ~ x). In this use, the ~ x part of the tilde expression identifies the input name, just as does the \\(x\\) in \\(g(x) \\equiv ...\\). You’ll also use tilde expressions for graphics and operations such as differentiation and anti-differentiation.\n\nThose familiar with R may be tempted to use the native function-building syntax, which looks like\n\ng <- function(x, a, b) {\n  a*x + b\n}\n\nWe strongly encourage you to use makeFun() instead. One reason is to reinforce the use of tilde expressions which are needed to identify the “with-respect-to” input in differentiation and anti-differentiation, as well as the frame of a graph. Another reason has to do with rules of scoping in computer languages, which have no obvious analog in mathematical notation. We prefer to leave scoping to a computer science class, rather than making it a pre-requisite for calculus. makeFun() avoids the scoping difficulties.\n\nDifferential notation. Historically, Leibniz’s lovely ratio notation, for instance, \\[\\frac{dy}{dx}\\ ,\\] helped generations of students learn differential calculus and see the connections to integral calculus. It is, however, wordy, which is why other notations—\\(f'\\) or \\(\\dot{x}\\) or \\(f^{(1)}\\) so often appear. But Leibniz could hardly have anticipated a future in which writing is done mainly with keyboards and linear sequences of characters. There is no mainstream computer language in which df/dx or f' or \\dot{x} or f^{(1)} are valid names. To simplify the use of the computer, we use \\(\\partial_x y\\) notation for differentiation. This can be easily morphed into a legal computer name: dx_y. We use \\(\\partial\\) instead of the Latin \\(d\\), partly to mark differentiation as something special and partly because we will use notation like \\(\\partial_{xt} g\\) when dealing with functions of multiple variables, or \\(\\partial_{xx} f\\) for second derivatives.\n\nThe book is designed to support six to eight credit hours of calculus study. The algebra pre-requisites are kept to a minimum, trigonometry beyond sines and cosines is not needed. In the starting “Preliminaries” part of the book nine “pattern-book” algebraic functions are introduced that form the basis for modeling work. “Preliminaries” also introduces computing notation, particularly that used for graphing functions.\n“Modeling,” Block I, introduces topics that are essential to the rest of the book and is worth spending considerable class time on regardless of the previous experience of students. Block II, “Differentiation,” is self-explanatory to a calculus instructor. Absence of extensive drill on symbolic differentiation of obscure functions or the use of Taylor polynomials or l’Hopital’s rule to provide even more drill is entirely intentional. Much more important that students master differentiation of the nine pattern-book functions and their parameterized version.\nBlock III, “Vectors and linear combinations,” does not depend on previously covering differentiation. The sequence Preliminaries-Modeling-Vectors could make a suitable 3- or 4-credit course for students entering data science. Block III might have been reasonably titled “Linear algebra.” But the universal emphasis on determinants and inverses of square matrices in a conventional linear algebra course is not a suitable introduction for working with data, and we did not want to suggest that all the conventional topics of linear algebra are included.\nBlock IV, “Accumulation,” builds on Block II, where differentiation is treated less as an algebraic process than as a relationship between functions. Our focus is on occasions when anti-differentiation is a useful modeling tool for extracting certain forms of information from a function. Instructors are advised to minimize or wholly avoid the area-under-a-curve metaphor. Like cigarettes, that metaphor is addictive and creates dis-ease with the more important roles for accumulation in contexts like dynamics. The final chapter of Block IV is about symbolic integration of functions constructed from from the pattern-book. Including it is a concession to administrative practices at universities where topics like “integration by parts” are included in hard-to-change course-catalog copy. Those techniques are not used elsewhere in the book.\nBlock V, “Dynamics,” introduces systems, that is, wholes made of multiple connected parts. Although the context used is differential equations, techniques for finding solutions are not central. More important are the phenomena (e.g. oscillation), the opportunities for modeling and showing how simple mathematical models can provide insight to otherwise seemingly complex natural and social systems, extension of the linear-algebra material from Block III to eigenvalues and eigenvectors, and a glimpse at the surprisingly close connection between exponentials and sinusoids.\nThe last block, “Manifestations,” is arranged along different lines than the previous chapters. The point is to show how calculus operations show themselves in a wide variety of contexts. We are not making up opportunities for more drill in symbolic differentiation and anti-differentiation. In the “Probability” chapter, to give an example, what’s central is the relationships between functions. One of these relationships is standard in calculus books, that between what’s called the CDF and the PDF. Less basic and not at all standard, the relationship between prior, likelihood, and posterior functions. It is not required to cover all the chapters in “Manifestations.” They do not much depend one on the other. Choose the ones that are best suited to the directions in which your students are heading. And the topics need not be delayed to the end of the course. For instance, the constrained optimization topic in “Optimization” can be handled with the material up to Block IV.\nMany highly expert calculus instructors have taught with these materials. Some of their experiences may be relevant to instructors who haven’t yet used MOSAIC Calculus. First, the experts are surprised by how many esteemed, traditional calculus topics are given short shrift or even omitted altogether, and even more surprised that their exclusion does not diminish the course. Second, many experts find that the calculus in this book is not calculus as they have been trained to think about it, but that nonetheless “it works.” Third, instructors who try to avoid spending class time on the computational elements of the book find that their students echo the avoidance. As these instructors go through their first year, they discover that there are only a handful of computational patterns (e.g. tilde expressions, domains) and that students would have avoided many headaches by facing them head-on from the start of the course. Some advice: Don’t think that you have to learn R before you can master using R to teach this book. The mosaic software that powers this book is a better place to start than with the many more general introductions and tutorials on R computing available in printed and video form.\nMost universally, even the expert instructors find they are unfamiliar with tranches of the material. Leading examples are dimensions of measurement, splines, mechanics (e.g. torque), the uses of orthogonalization, and, broadly, dynamics. Teaching unfamiliar material is admittedly stressful, but highly beneficial to yourself and your students. Dimensions and units, in particular, are a great guide to thinking; take every opportunity to ask your class what are the dimensions of the inputs to and outputs from a function and whether an operation makes sense in terms of dimensions. Consistently, the experts find that thinking about physical dimension gives them unexpected insight into the tasks and methods of calculus.\n\nDaniel Kaplan, Saint Paul, Minnesota, July 2022\n\n\n\n\nThis project was initiated by the Mathematical Sciences department at the US Air Force Academy. They recognized that a traditional calculus introduction is ill-suited to the needs of STEM in the 21st century.\nCritical support was given by the ARDI Foundation which awarded the Holland H. Coors Chair in Education Technology to one of the project members, Daniel Kaplan. This made possible a year-long residency at USAFA during which time he was able to work unhindered on this project.\nMacalester College, where Kaplan is DeWitt Wallace Professor of Mathematics, Statistics, and Computer science, was the site where the overall framework and many of the materials for a STEM-oriented calculus were developed. Particularly important in the germination were David Bressoud and Jan Serie, respectively chairs of the Macalester math and biology departments, as well as Prof. Thomas Halverson and Prof. Karen Saxe, who volunteered to team teach with Kaplan the first prototype course. Early grant support from the Howard Hughes Medical Foundation and the Keck Foundation provided the resources to carry the prototype course to a point of development where it became the entryway to calculus for Macalester students.\nProfs. Randall Pruim (Calvin University) and Nicholas Horton (Amherst College) were essential collaborators in developing software to support calculus in R. They and Kaplan formed the core team of Project MOSAIC, which was supported by the US National Science Foundation (NSF DUE-0920350).\nJoel Kilty and Alex McAllister at Centre College admired the Macalester course and devoted much work and ingenuity to write a textbook, Mathematical Modeling and Applied Calculus (Oxford Univ. Press), implementing their own version. Their textbook enabled us to reduce the use of sketchy notes in the first offering of this course at USAFA."
  }
]